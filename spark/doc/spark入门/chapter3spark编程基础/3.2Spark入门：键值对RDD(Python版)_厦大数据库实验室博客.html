<!DOCTYPE html>
<html lang="zh-CN"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Spark入门：键值对RDD(Python版)_厦大数据库实验室博客</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="renderer" content="webkit">
<link rel="dns-prefetch" href="http://cdn.staticfile.org/">
<link rel="dns-prefetch" href="http://s.w.org/">
<link rel="stylesheet" id="yarppWidgetCss-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/widget.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-quicklatex-format-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/quicklatex-format.css" type="text/css" media="all">
<link rel="stylesheet" id="bootstrap-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/bootstrap.css" type="text/css" media="all">
<link rel="stylesheet" id="font-awesome-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/font-awesome.css" type="text/css" media="all">
<link rel="stylesheet" id="power-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/style.css" type="text/css" media="all">
<link rel="stylesheet" id="google-code-prettify-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.css" type="text/css" media="all">
<script type="text/javascript" async="" charset="utf-8" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/core.js"></script><script src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/hm.js"></script><script src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/z_stat.js"></script><script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery_002.js"></script>
<script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery.js"></script>
<script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery-migrate.js"></script>
<script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-quicklatex-frontend.js"></script>
<link rel="https://api.w.org/" href="http://dblab.xmu.edu.cn/blog/wp-json/">
<link rel="prev" title="Python：Python安装" href="http://dblab.xmu.edu.cn/blog/1703-2/">
<link rel="next" title="Spark入门：共享变量(Python版)" href="http://dblab.xmu.edu.cn/blog/1707-2/">
<link rel="canonical" href="http://dblab.xmu.edu.cn/blog/1706-2/">
<link rel="alternate" type="application/json+oembed" href="http://dblab.xmu.edu.cn/blog/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fdblab.xmu.edu.cn%2Fblog%2F1706-2%2F">
<!--[if lt IE 9]>
<script src="http://dblab.xmu.edu.cn/blog/wp-content/themes/power/js/html5shiv.js"></script>
<![endif]-->
</head>

<body class="post-template-default single single-post postid-1706 single-format-standard group-blog">
<div class="container site-page">

<div class="row">
	<div class="col-sm-3 site-infos">
		<h4 class="site-title">
			<a href="http://dblab.xmu.edu.cn/blog/" title="厦大数据库实验室博客" rel="home">厦大数据库实验室博客</a>
		</h4>
		<div class="site-description">总结、分享、收获<p><a href="http://dblab.xmu.edu.cn/" title="厦大数据库实验室">实验室主页</a></p></div>

		<nav class="main-navigation" role="navigation">
			<div class="menu-primary-container"><ul id="menu-primary" class="menu menu-level-1"><li id="menu-item-80" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/">首页</a></li>
<li id="menu-item-85" class="menu-item item-level-1 current-path"><a href="http://dblab.xmu.edu.cn/blog/category/big-data/">大数据</a></li>
<li id="menu-item-676" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/databases/">数据库</a></li>
<li id="menu-item-87" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/data-mining/">数据挖掘</a></li>
<li id="menu-item-86" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/others/">其他</a></li>
</ul></div>		</nav><!-- #site-navigation -->

		<div class="search"><form role="search" method="get" class="search-form" action="http://dblab.xmu.edu.cn/blog/">
				<label>
					<span class="screen-reader-text">搜索：</span>
					<input class="search-field" placeholder="搜索…" name="s" type="search">
				</label>
				<input class="search-submit" value="搜索" type="submit">
			</form></div>
	</div>
	<div class="col-sm-9 site-main">

					<article id="post-1706" class="post-1706 post type-post status-publish format-standard hentry category-big-data">
	<header class="entry-header">
		<h1 class="entry-title">Spark入门：键值对RDD(Python版)</h1>

		<div class="entry-meta">
			<span class="author"><i class="fa fa-user"></i> 阮榕城</span><span class="date"><i class="fa fa-calendar"></i> <time datetime="2017-12-05T17:16:41+00:00">2017年12月5日</time> <span class="updated">(updated: <time class="updated" datetime="2017-12-08T11:04:35+00:00">2017年12月8日</time>)</span></span><span class="views" id="views"><i class="fa fa-eye"></i> 4100</span>		</div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div class="entry-content">
		<div class="bigdata-book">
			<a href="http://dblab.xmu.edu.cn/post/5899/" title="2019年1月20日寒假大数据师资培训班" target="_blank"><img src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/peixunban2019-01-20.jpg" alt="2019年1月20日寒假大数据师资培训班"></a>
		</div>
		<p>【版权声明】博客内容由厦门大学数据库实验室拥有版权，未经允许，请勿转载！<br>
<a href="http://dblab.xmu.edu.cn/blog/1709-2/" target="_blank">返回Spark教程首页</a></p>
<p>虽然RDD中可以包含任何类型的对象，但是“键值对”是一种比较常见的RDD元素类型，分组和聚合操作中经常会用到。<br>
Spark操作中经常会用到“键值对RDD”（Pair RDD），用于完成聚合计算。普通RDD里面存储的数据类型是Int、String等，而“键值对RDD”里面存储的数据类型是“键值对”。<br>
<span id="more-1706"></span></p>
<h1>创建RDD之前的准备工作</h1>
<p>在即将进行相关的实践操作之前，我们首先要登录Linux系统（本教程统一采用hadoop用户登录），然后，打开命令行“终端”，请按照下面的命令启动Hadoop中的HDFS组件：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd  </span><span class="pln">/usr/local/hadoop</span></li><li class="L1"><span class="pln">./sbin/start-dfs.sh</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>然后，我们按照下面命令启动pyspark：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/spark</span></li><li class="L1"><span class="pln">./bin/pyspark</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>然后，新建第二个“终端”，方法是，在前面已经建设的第一个终端窗口的左上方，点击“终端”菜单，在弹出的子菜单中选择“新建终端”，就可以打开第
二个终端窗口，现在，我们切换到第二个终端窗口，在第二个终端窗口中，执行以下命令，进入之前已经创建好的“/usr/local/spark
/mycode/”目录，在这个目录下新建pairrdd子目录，用来存放本章的代码和相关文件：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/spark/mycode/</span></li><li class="L1"><span class="kwd">mkdir </span><span class="pln">pairrdd</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>然后，使用vim编辑器，在pairrdd目录下新建一个word.txt文件，你可以在文件里面随便输入几行英文语句用来测试。</p>
<p>经过上面的准备工作以后，我们就可以开始创建RDD了。</p>
<h1>键值对RDD的创建</h1>
<h2>第一种创建方式：从文件中加载</h2>
<p>我们可以采用多种方式创建键值对RDD，其中一种主要方式是使用map()函数来实现，如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln">  lines </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/mycode/pairrdd/word.txt"</span><span class="pun">)</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD </span><span class="pun">=</span><span class="pln"> lines</span><span class="pun">.</span><span class="pln">flatMap</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> line </span><span class="pun">:</span><span class="pln"> line</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">" "</span><span class="pun">)).</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> word </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">word</span><span class="pun">,</span><span class="lit">1</span><span class="pun">))</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L3"><span class="pun">(</span><span class="pln">i</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L4"><span class="pun">(</span><span class="pln">love</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L5"><span class="pun">(</span><span class="pln">hadoop</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L6"><span class="pun">(</span><span class="pln">i</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L7"><span class="pun">(</span><span class="pln">love</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L8"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L9"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L0"><span class="pun">(</span><span class="kwd">is</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L1"><span class="pun">(</span><span class="pln">fast</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L2"><span class="pun">(</span><span class="pln">than</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L3"><span class="pun">(</span><span class="pln">hadoop</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>我们之前在“第一个Spark应用程序:WordCount”章节已经详细解释过类似代码，所以，上面代码不再做细节分析。从代码执行返回信
息：pairRDD: org.apache.spark.rdd.RDD[(String, Int)] = MapPartitionsRDD[3]
 at map at :29，可以看出，返回的结果是键值对类型的RDD，即RDD[(String, 
Int)]。从pairRDD.foreach(println)执行的打印输出结果也可以看到，都是由(单词,1)这种形式的键值对。</p>
<h2>第二种创建方式：通过并行集合（列表）创建RDD</h2>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> list </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="str">"Hadoop"</span><span class="pun">,</span><span class="str">"Spark"</span><span class="pun">,</span><span class="str">"Hive"</span><span class="pun">,</span><span class="str">"Spark"</span><span class="pun">]</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rdd </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">(</span><span class="pln">list</span><span class="pun">)</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD </span><span class="pun">=</span><span class="pln"> rdd</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> word </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">word</span><span class="pun">,</span><span class="lit">1</span><span class="pun">))</span></li><li class="L3"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L4"><span class="pun">(</span><span class="typ">Hadoop</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L5"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L6"><span class="pun">(</span><span class="typ">Hive</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L7"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>我们下面实例都是采用这种方式得到的pairRDD作为基础。</p>
<h1>常用的键值对转换操作</h1>
<p>常用的键值对转换操作包括reduceByKey()、groupByKey()、sortByKey()、join()、cogroup()等，下面我们通过实例来介绍。</p>
<h2>reduceByKey(func)</h2>
<p>reduceByKey(func)的功能是，使用func函数合并具有相同键的值。比如，reduceByKey((a,b) =&gt; 
a+b)，有四个键值对(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)，对具有相同key的键值
对进行合并后的结果就是：(“spark”,3)、(“hadoop”,8)。可以看出，(a,b) =&gt; 
a+b这个Lamda表达式中，a和b都是指value，比如，对于两个具有相同key的键值对(“spark”,1)、(“spark”,2)，a就是
1，b就是2。<br>
我们对上面第二种方式创建得到的pairRDD进行reduceByKey()操作，代码如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">reduceByKey</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> a</span><span class="pun">,</span><span class="pln">b </span><span class="pun">:</span><span class="pln"> a</span><span class="pun">+</span><span class="pln">b</span><span class="pun">).</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L1"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span></li><li class="L2"><span class="pun">(</span><span class="typ">Hive</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L3"><span class="pun">(</span><span class="typ">Hadoop</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>groupByKey()</h2>
<p>groupByKey()的功能是，对具有相同键的值进行分组。比如，对四个键值对(“spark”,1)、(“spark”,2)、
(“hadoop”,3)和(“hadoop”,5)，采用groupByKey()后得到的结果是：(“spark”,(1,2))和
(“hadoop”,(3,5))。<br>
我们对上面第二种方式创建得到的pairRDD进行groupByKey()操作，代码如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">groupByKey</span><span class="pun">()</span></li><li class="L1"><span class="typ">PythonRDD</span><span class="pun">[</span><span class="lit">11</span><span class="pun">]</span><span class="pln"> at RDD at </span><span class="typ">PythonRDD</span><span class="pun">.</span><span class="pln">scala</span><span class="pun">:</span><span class="lit">48</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">groupByKey</span><span class="pun">().</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L3"><span class="pun">(</span><span class="str">'spark'</span><span class="pun">,</span><span class="pln"> </span><span class="pun">&lt;</span><span class="pln">pyspark</span><span class="pun">.</span><span class="pln">resultiterable</span><span class="pun">.</span><span class="typ">ResultIterable</span><span class="pln"> object at </span><span class="lit">0x7f1869f81f60</span><span class="pun">&gt;)</span></li><li class="L4"><span class="pun">(</span><span class="str">'hadoop'</span><span class="pun">,</span><span class="pln"> </span><span class="pun">&lt;</span><span class="pln">pyspark</span><span class="pun">.</span><span class="pln">resultiterable</span><span class="pun">.</span><span class="typ">ResultIterable</span><span class="pln"> object at </span><span class="lit">0x7f1869f81f60</span><span class="pun">&gt;)</span></li><li class="L5"><span class="pun">(</span><span class="str">'hive'</span><span class="pun">,</span><span class="pln"> </span><span class="pun">&lt;</span><span class="pln">pyspark</span><span class="pun">.</span><span class="pln">resultiterable</span><span class="pun">.</span><span class="typ">ResultIterable</span><span class="pln"> object at </span><span class="lit">0x7f1869f81f60</span><span class="pun">&gt;)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>keys()</h2>
<p>keys()只会把键值对RDD中的key返回形成一个新的RDD。比如，对四个键值对(“spark”,1)、(“spark”,2)、
(“hadoop”,3)和(“hadoop”,5)构成的RDD，采用keys()后得到的结果是一个RDD[Int]，内容是
{“spark”,”spark”,”hadoop”,”hadoop”}。<br>
我们对上面第二种方式创建得到的pairRDD进行keys操作，代码如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">keys</span><span class="pun">()</span></li><li class="L1"><span class="typ">PythonRDD</span><span class="pun">[</span><span class="lit">20</span><span class="pun">]</span><span class="pln"> at RDD at </span><span class="typ">PythonRDD</span><span class="pun">.</span><span class="pln">scala</span><span class="pun">:</span><span class="lit">48</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">keys</span><span class="pun">().</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L3"><span class="typ">Hadoop</span></li><li class="L4"><span class="typ">Spark</span></li><li class="L5"><span class="typ">Hive</span></li><li class="L6"><span class="typ">Spark</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>values()</h2>
<p>values()只会把键值对RDD中的value返回形成一个新的RDD。比如，对四个键值对(“spark”,1)、(“spark”,2)、
(“hadoop”,3)和(“hadoop”,5)构成的RDD，采用values()后得到的结果是一个RDD[Int]，内容是
{1,2,3,5}。<br>
我们对上面第二种方式创建得到的pairRDD进行values()操作，代码如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">scala</span><span class="pun">&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">values</span><span class="pun">()</span></li><li class="L1"><span class="typ">PythonRDD</span><span class="pun">[</span><span class="lit">22</span><span class="pun">]</span><span class="pln"> at RDD at </span><span class="typ">PythonRDD</span><span class="pun">.</span><span class="pln">scala</span><span class="pun">:</span><span class="lit">48</span></li><li class="L2"><span class="pln">scala</span><span class="pun">&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">values</span><span class="pun">().</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L3"><span class="lit">1</span></li><li class="L4"><span class="lit">1</span></li><li class="L5"><span class="lit">1</span></li><li class="L6"><span class="lit">1</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>sortByKey()</h2>
<p>sortByKey()的功能是返回一个根据键排序的RDD。<br>
我们对上面第二种方式创建得到的pairRDD进行keys操作，代码如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">sortByKey</span><span class="pun">()</span></li><li class="L1"><span class="typ">PythonRDD</span><span class="pun">[</span><span class="lit">30</span><span class="pun">]</span><span class="pln"> at RDD at </span><span class="typ">PythonRDD</span><span class="pun">.</span><span class="pln">scala</span><span class="pun">:</span><span class="lit">48</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">sortByKey</span><span class="pun">().</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L3"><span class="pun">(</span><span class="typ">Hadoop</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L4"><span class="pun">(</span><span class="typ">Hive</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L5"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li><li class="L6"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>mapValues(func)</h2>
<p>我们经常会遇到一种情形，我们只想对键值对RDD的value部分进行处理，而不是同时对key和value进行处理。对于这种情形，Spark提
供了mapValues(func)，它的功能是，对键值对RDD中的每个value都应用一个函数，但是，key不会发生变化。比如，对四个键值对
(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5)构成的pairRDD，如果执行
pairRDD.mapValues(lambda x : 
x+1)，就会得到一个新的键值对RDD，它包含下面四个键值对(“spark”,2)、(“spark”,3)、(“hadoop”,4)和
(“hadoop”,6)。<br>
我们对上面第二种方式创建得到的pairRDD进行keys操作，代码如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">mapValues</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x </span><span class="pun">:</span><span class="pln"> x</span><span class="pun">+</span><span class="lit">1</span><span class="pun">)</span></li><li class="L1"><span class="typ">PythonRDD</span><span class="pun">[</span><span class="lit">38</span><span class="pun">]</span><span class="pln"> at RDD at </span><span class="typ">PythonRDD</span><span class="pun">.</span><span class="pln">scala</span><span class="pun">:</span><span class="lit">48</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD</span><span class="pun">.</span><span class="pln">mapValues</span><span class="pun">(</span><span class="pln"> </span><span class="kwd">lambda</span><span class="pln"> x </span><span class="pun">:</span><span class="pln"> x</span><span class="pun">+</span><span class="lit">1</span><span class="pun">).</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L3"><span class="pun">(</span><span class="typ">Hadoop</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span></li><li class="L4"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span></li><li class="L5"><span class="pun">(</span><span class="typ">Hive</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span></li><li class="L6"><span class="pun">(</span><span class="typ">Spark</span><span class="pun">,</span><span class="lit">2</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>join</h2>
<p>join(连接)操作是键值对常用的操作。“连接”(join)这个概念来自于关系数据库领域，因此，join的类型也和关系数据库中的join一
样，包括内连接(join)、左外连接(leftOuterJoin)、右外连接(rightOuterJoin)等。最常用的情形是内连接，所
以，join就表示内连接。<br>
对于内连接，对于给定的两个输入数据集(K,V1)和(K,V2)，只有在两个数据集中都存在的key才会被输出，最终得到一个(K,(V1,V2))类型的数据集。</p>
<p>比如，pairRDD1是一个键值对集合{(“spark”,1)、(“spark”,2)、(“hadoop”,3)和
(“hadoop”,5)}，pairRDD2是一个键值对集合{(“spark”,”fast”)}，那
么，pairRDD1.join(pairRDD2)的结果就是一个新的RDD，这个新的RDD是键值对集合{(“spark”,1,”fast”),
(“spark”,2,”fast”)}。对于这个实例，我们下面在pyspark中运行一下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD1 </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">([(</span><span class="str">'spark'</span><span class="pun">,</span><span class="lit">1</span><span class="pun">),(</span><span class="str">'spark'</span><span class="pun">,</span><span class="lit">2</span><span class="pun">),(</span><span class="str">'hadoop'</span><span class="pun">,</span><span class="lit">3</span><span class="pun">),(</span><span class="str">'hadoop'</span><span class="pun">,</span><span class="lit">5</span><span class="pun">)])</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD2 </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">([(</span><span class="str">'spark'</span><span class="pun">,</span><span class="str">'fast'</span><span class="pun">)])</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD1</span><span class="pun">.</span><span class="pln">join</span><span class="pun">(</span><span class="pln">pairRDD2</span><span class="pun">)</span></li><li class="L3"><span class="typ">PythonRDD</span><span class="pun">[</span><span class="lit">49</span><span class="pun">]</span><span class="pln"> at RDD at </span><span class="typ">PythonRDD</span><span class="pun">.</span><span class="pln">scala</span><span class="pun">:</span><span class="lit">48</span><span class="pln"> </span></li><li class="L4"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> pairRDD1</span><span class="pun">.</span><span class="pln">join</span><span class="pun">(</span><span class="pln">pairRDD2</span><span class="pun">).</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h1>一个综合实例</h1>
<p>题目：给定一组键值对(“spark”,2),(“hadoop”,6),(“hadoop”,4),(“spark”,6)，键值对的key表示图书名称，value表示某天图书销量，请计算每个键对应的平均值，也就是计算每种图书的每天平均销量。<br>
很显然，对于上面的题目，结果是很显然的，(“spark”,4),(“hadoop”,5)。<br>
下面，我们在pyspark中演示代码执行过程：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rdd </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">([(</span><span class="str">"spark"</span><span class="pun">,</span><span class="lit">2</span><span class="pun">),(</span><span class="str">"hadoop"</span><span class="pun">,</span><span class="lit">6</span><span class="pun">),(</span><span class="str">"hadoop"</span><span class="pun">,</span><span class="lit">4</span><span class="pun">),(</span><span class="str">"spark"</span><span class="pun">,</span><span class="lit">6</span><span class="pun">)])</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rdd</span><span class="pun">.</span><span class="pln">mapValues</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)).</span><span class="pln">reduceByKey</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x</span><span class="pun">,</span><span class="pln">y </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]+</span><span class="pln">y</span><span class="pun">[</span><span class="lit">0</span><span class="pun">],</span><span class="pln">x</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> y</span><span class="pun">[</span><span class="lit">1</span><span class="pun">])).</span><span class="pln">mapValues</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]</span><span class="pln"> </span><span class="pun">/</span><span class="pln"> x</span><span class="pun">[</span><span class="lit">1</span><span class="pun">])).</span><span class="pln">collect</span><span class="pun">()</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>要注意，上面语句中，mapValues(lambda x : (x,1))中出现了变量x，reduceByKey(lambda x,y :
 (x[0]+y[0],x[1]+ y[1]))中也出现了变量x，mapValues(lambda x : (x[0] / 
x[1]))也出现了变量x。但是，必须要清楚，这三个地方出现的x，虽然都具有相同的变量名称x，但是，彼此之间没有任何关系，它们都处在不同的变量作
用域内。如果你觉得这样会误导自己，造成理解上的掌握，实际上，你可以把三个出现x的地方分别替换成x1、x2、x3也是可以的，但是，很显然没有必要这
么做。<br>
上面是完整的语句和执行过程，可能不太好理解，下面我们进行逐条语句分解给大家介绍。每条语句执行后返回的屏幕信息，可以帮助大家更好理解语句的执行效果，比如生成了什么类型的RDD。</p>
<p>（1）首先构建一个数组，数组里面包含了四个键值对，然后，调用parallelize()方法生成RDD，从执行结果反馈信息，可以看出，rdd类型是RDD[(String, Int)]。</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rdd </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">([(</span><span class="str">"spark"</span><span class="pun">,</span><span class="lit">2</span><span class="pun">),(</span><span class="str">"hadoop"</span><span class="pun">,</span><span class="lit">6</span><span class="pun">),(</span><span class="str">"hadoop"</span><span class="pun">,</span><span class="lit">4</span><span class="pun">),(</span><span class="str">"spark"</span><span class="pun">,</span><span class="lit">6</span><span class="pun">)])</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>（2）针对构建得到的rdd，我们调用mapValues()函数，把rdd中的每个每个键值对(key,value)的value部分进行修改，
把value转换成键值对(value,1)，其中，数值1表示这个key在rdd中出现了1次，为什么要记录出现次数呢？因为，我们最终要计算每个
key对应的平均值，所以，必须记住这个key出现了几次，最后用value的总和除以key的出现次数，就是这个key对应的平均值。比如，键值对
(“spark”,2)经过mapValues()函数处理后，就变成了(“spark”,(2,1))，其中，数值1表示“spark”这个键的1次出
现。下面就是rdd.mapValues()操作在spark-shell中的执行演示：<br>
scala&gt; rdd.mapValues(x =&gt; (x,1)).collect()<br>
res23: Array[(String, (Int, Int))] = Array((spark,(2,1)), (hadoop,(6,1)), (hadoop,(4,1)), (spark,(6,1)))<br>
上面语句中，collect()是一个行动操作，功能是以数组的形式返回数据集中的所有元素，当我们要实时查看一个RDD中的元素内容时，就可以调用collect()函数。</p>
<p>（3）然后，再对上一步得到的RDD调用reduceByKey()函数，在spark-shell中演示如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rdd</span><span class="pun">.</span><span class="pln">mapValues</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)).</span><span class="pln">reduceByKey</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x</span><span class="pun">,</span><span class="pln">y </span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]+</span><span class="pln">y</span><span class="pun">[</span><span class="lit">0</span><span class="pun">],</span><span class="pln">x</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> y</span><span class="pun">[</span><span class="lit">1</span><span class="pun">])).</span><span class="pln">collect</span><span class="pun">()</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>这里，必须要十分准确地理解reduceByKey()函数的功能。可以参考上面我们对该函数的介绍，reduceByKey(func)的功能是
使用func函数合并具有相同键的值。这里的func函数就是Lamda表达式 x,y : (x[0]+y[0],x[1] + 
y[1])，这个表达式中，x和y都是value，而且是具有相同key的两个键值对所对应的value，比如，在这个例子中， 
(“hadoop”,(6,1))和(“hadoop”,(4,1))这两个键值对具有相同的key，所以，对于函数中的输入参数(x,y)而言，x就是
(6,1)，序列从0开始计算，x[0]表示这个键值对中的第1个元素6，x[1]表示这个键值对中的第二个元素1，y就是(4,1)，y[0]表示这个
键值对中的第1个元素4，y[1]表示这个键值对中的第二个元素1，所以，函数体(x[0]+y[0],x[1] + 
y[2])，相当于生成一个新的键值对(key,value)，其中，key是x[0]+y[0]，也就是6+4=10，value是x[1] + 
y[1]，也就是1+1=2，因此，函数体(x[0]+y[0],x[1] + 
y[1])执行后得到的value是(10,2)，但是，要注意，这个(10,2)是reduceByKey()函数执行后，”hadoop”这个key
对应的value，也就是，实际上reduceByKey()函数执行后，会生成一个键值对(“hadoop”,(10,2))，其中，10表示
hadoop书籍的总销量，2表示两天。同理，reduceByKey()函数执行后会生成另外一个键值对(“spark”,(8,2))。</p>
<p>(4)最后，就可以求出最终结果。我们可以对上面得到的两个键值对(“hadoop”,(10,2))和(“spark”,(8,2))所构成的
RDD执行mapValues()操作，得到每种书的每天平均销量。当第一个键值对(“hadoop”,(10,2))输入给mapValues(x 
=&gt; (x[0] / x[1]))操作时，key是”hadoop”，保持不变，value是(10,2)，会被赋值给Lamda表达式x 
=&gt; (x[0] / 
x[1]中的x，因此，x的值就是(10,2)，x[0]就是10，表示hadoop书总销量是10，x[1]就是2，表示2天，因此，hadoop书籍
的每天平均销量就是x[0] / 
x[1]，也就是5。mapValues()输出的一个键值对就是(“hadoop”,5)。同理，当把(“spark”,(8,2))输入给
mapValues()时，会计算得到另外一个键值对(“spark”,4)。在pyspark中演示如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rdd</span><span class="pun">.</span><span class="pln">mapValues</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">,</span><span class="lit">1</span><span class="pun">)).</span><span class="pln">reduceByKey</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x</span><span class="pun">,</span><span class="pln">y</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]+</span><span class="pln">y</span><span class="pun">[</span><span class="lit">0</span><span class="pun">],</span><span class="pln">x</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]+</span><span class="pln">y</span><span class="pun">[</span><span class="lit">1</span><span class="pun">])).</span><span class="pln">mapValues</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">x</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]/</span><span class="pln">x</span><span class="pun">[</span><span class="lit">2</span><span class="pun">])).</span><span class="pln">collect</span><span class="pun">()</span></li><li class="L1"><span class="pln"> </span><span class="pun">[(</span><span class="str">'hadoop'</span><span class="pun">,</span><span class="pln"> </span><span class="lit">5.0</span><span class="pun">),</span><span class="pln"> </span><span class="pun">(</span><span class="str">'spark'</span><span class="pun">,</span><span class="pln"> </span><span class="lit">4.0</span><span class="pun">)]</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
			</div><!-- .entry-content -->

	<footer class="entry-footer">
		<div class="entry-author">
			<div class="author-title">本文作者</div>
			
		<div class="author-avatar"><img src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/2.jpg" alt="阮榕城" class="avatar avatar-thumbnail wp-user-avatar wp-user-avatar-thumbnail alignnone photo"></div>
		<div class="author-info">
			<p class="author-name"><a href="http://dblab.xmu.edu.cn/blog/author/ruanrongcheng/">阮榕城</a></p>
			<p class="author-desc">磨人的小妖精！</p>
			<p class="author-contact"><a href="http://www.nekomiao.me/" target="_blank" title="个人主页" class="homepage"><i class="fa fa-home"></i>www.nekomiao.me</a><i class="fa fa-envelope"></i><span class="envelope">moc.qq@crnaur</span></p>
		</div>
			</div>
		<div class="entry-info">
			<span class="permalink"><i class="fa fa-external-link"></i> <a href="http://dblab.xmu.edu.cn/blog/1706-2/" title="Spark入门：键值对RDD(Python版)">http://dblab.xmu.edu.cn/blog/1706-2/</a></span><span class="category"><i class="fa fa-folder-open-o"></i> <a href="http://dblab.xmu.edu.cn/blog/category/big-data/" rel="category tag">大数据</a></span>		</div>
		<div class="yarpp-related yarpp-related-none">
</div>
	</footer><!-- .entry-footer -->
</article><!-- #post-## -->
			</div>
</div><!-- .row -->

	<div class="row">
		<div class="col-sm-3"></div>
		<div class="col-sm-9 site-footer">
			© 2014 <a href="http://dblab.xmu.edu.cn/">厦大数据库实验室</a>
					</div>
	</div>
</div><!-- .container -->
<link rel="stylesheet" id="yarppRelatedCss-css" href="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/related.css" type="text/css" media="all">
<script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.js"></script>
<script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/power.js"></script>
<script type="text/javascript" src="3.2Spark%E5%85%A5%E9%97%A8%EF%BC%9A%E9%94%AE%E5%80%BC%E5%AF%B9RDD(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-embed.js"></script>

<div class="back-to-top" id="back-to-top" title="嗖的就上去了！" style="display: block;"><span><i class="fa fa-chevron-up"></i></span></div></body></html>