<!DOCTYPE html>
<html lang="zh-CN"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Spark2.1.0+入门：从RDD转换得到DataFrame(Python版)_厦大数据库实验室博客</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="renderer" content="webkit">
<link rel="dns-prefetch" href="http://cdn.staticfile.org/">
<link rel="dns-prefetch" href="http://s.w.org/">
<link rel="stylesheet" id="yarppWidgetCss-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/widget.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-quicklatex-format-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/quicklatex-format.css" type="text/css" media="all">
<link rel="stylesheet" id="bootstrap-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/bootstrap.css" type="text/css" media="all">
<link rel="stylesheet" id="font-awesome-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/font-awesome.css" type="text/css" media="all">
<link rel="stylesheet" id="power-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/style.css" type="text/css" media="all">
<link rel="stylesheet" id="google-code-prettify-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.css" type="text/css" media="all">
<script type="text/javascript" async="" charset="utf-8" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/core.js"></script><script src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/hm.js"></script><script src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/z_stat.js"></script><script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery_002.js"></script>
<script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery.js"></script>
<script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery-migrate.js"></script>
<script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-quicklatex-frontend.js"></script>
<link rel="https://api.w.org/" href="http://dblab.xmu.edu.cn/blog/wp-json/">
<link rel="prev" title="Spark2.1.0入门：DataFrame的创建(Python版)" href="http://dblab.xmu.edu.cn/blog/1719-2/">
<link rel="next" title="Python：列表" href="http://dblab.xmu.edu.cn/blog/1721-2/">
<link rel="canonical" href="http://dblab.xmu.edu.cn/blog/1720-2/">
<link rel="alternate" type="application/json+oembed" href="http://dblab.xmu.edu.cn/blog/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fdblab.xmu.edu.cn%2Fblog%2F1720-2%2F">
<!--[if lt IE 9]>
<script src="http://dblab.xmu.edu.cn/blog/wp-content/themes/power/js/html5shiv.js"></script>
<![endif]-->
</head>

<body class="post-template-default single single-post postid-1720 single-format-standard group-blog">
<div class="container site-page">

<div class="row">
	<div class="col-sm-3 site-infos">
		<h4 class="site-title">
			<a href="http://dblab.xmu.edu.cn/blog/" title="厦大数据库实验室博客" rel="home">厦大数据库实验室博客</a>
		</h4>
		<div class="site-description">总结、分享、收获<p><a href="http://dblab.xmu.edu.cn/" title="厦大数据库实验室">实验室主页</a></p></div>

		<nav class="main-navigation" role="navigation">
			<div class="menu-primary-container"><ul id="menu-primary" class="menu menu-level-1"><li id="menu-item-80" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/">首页</a></li>
<li id="menu-item-85" class="menu-item item-level-1 current-path"><a href="http://dblab.xmu.edu.cn/blog/category/big-data/">大数据</a></li>
<li id="menu-item-676" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/databases/">数据库</a></li>
<li id="menu-item-87" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/data-mining/">数据挖掘</a></li>
<li id="menu-item-86" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/others/">其他</a></li>
</ul></div>		</nav><!-- #site-navigation -->

		<div class="search"><form role="search" method="get" class="search-form" action="http://dblab.xmu.edu.cn/blog/">
				<label>
					<span class="screen-reader-text">搜索：</span>
					<input class="search-field" placeholder="搜索…" name="s" type="search">
				</label>
				<input class="search-submit" value="搜索" type="submit">
			</form></div>
	</div>
	<div class="col-sm-9 site-main">

					<article id="post-1720" class="post-1720 post type-post status-publish format-standard hentry category-big-data">
	<header class="entry-header">
		<h1 class="entry-title">Spark2.1.0+入门：从RDD转换得到DataFrame(Python版)</h1>

		<div class="entry-meta">
			<span class="author"><i class="fa fa-user"></i> 阮榕城</span><span class="date"><i class="fa fa-calendar"></i> <time datetime="2017-12-07T14:44:55+00:00">2017年12月7日</time></span><span class="views" id="views"><i class="fa fa-eye"></i> 4805</span>		</div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div class="entry-content">
		<div class="bigdata-book">
			<a href="http://dblab.xmu.edu.cn/post/5899/" title="2019年1月20日寒假大数据师资培训班" target="_blank"><img src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/peixunban2019-01-20.jpg" alt="2019年1月20日寒假大数据师资培训班"></a>
		</div>
		<p>【版权声明】博客内容由厦门大学数据库实验室拥有版权，未经允许，请勿转载！<br>
<a href="http://dblab.xmu.edu.cn/blog/1709-2/" target="_blank">返回Spark教程首页</a><br>
Spark官网提供了两种方法来实现从RDD转换得到DataFrame，第一种方法是，利用反射来推断包含特定类型对象的RDD的schema，适用对已知数据结构的RDD转换；第二种方法是，使用编程接口，构造一个schema并将其应用在已知的RDD上。</p>
<p><span id="more-1720"></span></p>
<h1>利用反射机制推断RDD模式</h1>
<p>在利用反射机制推断RDD模式时,我们会用到toDF()方法<br>
下面是在pyspark中执行命令以及反馈的信息：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> </span><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">Row</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> </span><span class="kwd">def</span><span class="pln"> f</span><span class="pun">(</span><span class="pln">x</span><span class="pun">):</span></li><li class="L2"><span class="pun">...</span><span class="pln">     rel </span><span class="pun">=</span><span class="pln"> </span><span class="pun">{}</span></li><li class="L3"><span class="pun">...</span><span class="pln">     rel</span><span class="pun">[</span><span class="str">'name'</span><span class="pun">]</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> x</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]</span></li><li class="L4"><span class="pun">...</span><span class="pln">     rel</span><span class="pun">[</span><span class="str">'age'</span><span class="pun">]</span><span class="pln"> </span><span class="pun">=</span><span class="pln"> x</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]</span></li><li class="L5"><span class="pun">...</span><span class="pln">     </span><span class="kwd">return</span><span class="pln"> rel</span></li><li class="L6"><span class="pun">...</span><span class="pln"> </span></li><li class="L7"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/examples/src/main/resources/people.txt"</span><span class="pun">).</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> line </span><span class="pun">:</span><span class="pln"> line</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">','</span><span class="pun">)).</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> x</span><span class="pun">:</span><span class="pln"> </span><span class="typ">Row</span><span class="pun">(**</span><span class="pln">f</span><span class="pun">(</span><span class="pln">x</span><span class="pun">))).</span><span class="pln">toDF</span><span class="pun">()</span></li><li class="L8"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF</span><span class="pun">.</span><span class="pln">createOrReplaceTempView</span><span class="pun">(</span><span class="str">"people"</span><span class="pun">)</span><span class="pln">  </span><span class="pun">//必须注册为临时表才能供下面的查询使用</span></li><li class="L9"><span class="pln">&nbsp;</span></li><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> personsDF </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">(</span><span class="str">"select * from people"</span><span class="pun">)</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> personsDF</span><span class="pun">.</span><span class="pln">rdd</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> t </span><span class="pun">:</span><span class="pln"> </span><span class="str">"Name:"</span><span class="pun">+</span><span class="pln">t</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]+</span><span class="str">","</span><span class="pun">+</span><span class="str">"Age:"</span><span class="pun">+</span><span class="pln">t</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]).</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L2"><span class="pln">&nbsp;</span></li><li class="L3"><span class="typ">Name</span><span class="pun">:</span><span class="pln"> </span><span class="lit">19</span><span class="pun">,</span><span class="typ">Age</span><span class="pun">:</span><span class="typ">Justin</span></li><li class="L4"><span class="typ">Name</span><span class="pun">:</span><span class="pln"> </span><span class="lit">29</span><span class="pun">,</span><span class="typ">Age</span><span class="pun">:</span><span class="typ">Michael</span></li><li class="L5"><span class="typ">Name</span><span class="pun">:</span><span class="pln"> </span><span class="lit">30</span><span class="pun">,</span><span class="typ">Age</span><span class="pun">:</span><span class="typ">Andy</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h1>使用编程方式定义RDD模式</h1>
<p>使用createDataFrame(rdd, schema)编程方式定义RDD模式。</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln">  </span><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">Row</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln">  </span><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StructType</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> </span><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StructField</span></li><li class="L3"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> </span><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StringType</span></li><li class="L4"><span class="pln">&nbsp;</span></li><li class="L5"><span class="pun">//生成</span><span class="pln"> RDD</span></li><li class="L6"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleRDD </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/examples/src/main/resources/people.txt"</span><span class="pun">)</span></li><li class="L7"><span class="pln">&nbsp;</span></li><li class="L8"><span class="pun">//定义一个模式字符串</span></li><li class="L9"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> schemaString </span><span class="pun">=</span><span class="pln"> </span><span class="str">"name age"</span></li><li class="L0"><span class="pln">&nbsp;</span></li><li class="L1"><span class="pun">//根据模式字符串生成模式</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> fields </span><span class="pun">=</span><span class="pln"> list</span><span class="pun">(</span><span class="pln">map</span><span class="pun">(</span><span class="pln"> </span><span class="kwd">lambda</span><span class="pln"> fieldName </span><span class="pun">:</span><span class="pln"> </span><span class="typ">StructField</span><span class="pun">(</span><span class="pln">fieldName</span><span class="pun">,</span><span class="pln"> </span><span class="typ">StringType</span><span class="pun">(),</span><span class="pln"> nullable </span><span class="pun">=</span><span class="pln"> </span><span class="kwd">True</span><span class="pun">),</span><span class="pln"> schemaString</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">" "</span><span class="pun">)))</span></li><li class="L3"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> schema </span><span class="pun">=</span><span class="pln"> </span><span class="typ">StructType</span><span class="pun">(</span><span class="pln">fields</span><span class="pun">)</span></li><li class="L4"><span class="pun">//从上面信息可以看出，</span><span class="pln">schema</span><span class="pun">描述了模式信息，模式中包含</span><span class="pln">name</span><span class="pun">和</span><span class="pln">age</span><span class="pun">两个字段</span></li><li class="L5"><span class="pln">&nbsp;</span></li><li class="L6"><span class="pln">&nbsp;</span></li><li class="L7"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> rowRDD </span><span class="pun">=</span><span class="pln"> peopleRDD</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> line </span><span class="pun">:</span><span class="pln"> line</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">','</span><span class="pun">)).</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> attributes </span><span class="pun">:</span><span class="pln"> </span><span class="typ">Row</span><span class="pun">(</span><span class="pln">attributes</span><span class="pun">[</span><span class="lit">0</span><span class="pun">],</span><span class="pln"> attributes</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]))</span></li><li class="L8"><span class="pln">&nbsp;</span></li><li class="L9"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">createDataFrame</span><span class="pun">(</span><span class="pln">rowRDD</span><span class="pun">,</span><span class="pln"> schema</span><span class="pun">)</span></li><li class="L0"><span class="pln">&nbsp;</span></li><li class="L1"><span class="pun">//必须注册为临时表才能供下面查询使用</span></li><li class="L2"><span class="pln">scala</span><span class="pun">&gt;</span><span class="pln"> peopleDF</span><span class="pun">.</span><span class="pln">createOrReplaceTempView</span><span class="pun">(</span><span class="str">"people"</span><span class="pun">)</span></li><li class="L3"><span class="pln">&nbsp;</span></li><li class="L4"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> results </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">(</span><span class="str">"SELECT * FROM people"</span><span class="pun">)</span></li><li class="L5"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> results</span><span class="pun">.</span><span class="pln">rdd</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="pln"> </span><span class="kwd">lambda</span><span class="pln"> attributes </span><span class="pun">:</span><span class="pln"> </span><span class="str">"name: "</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> attributes</span><span class="pun">[</span><span class="lit">0</span><span class="pun">]+</span><span class="str">","</span><span class="pun">+</span><span class="str">"age:"</span><span class="pun">+</span><span class="pln">attributes</span><span class="pun">[</span><span class="lit">1</span><span class="pun">]).</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L6"><span class="pln">&nbsp;</span></li><li class="L7"><span class="pln">name</span><span class="pun">:</span><span class="pln"> </span><span class="typ">Michael</span><span class="pun">,</span><span class="pln">age</span><span class="pun">:</span><span class="pln"> </span><span class="lit">29</span></li><li class="L8"><span class="pln">name</span><span class="pun">:</span><span class="pln"> </span><span class="typ">Andy</span><span class="pun">,</span><span class="pln">age</span><span class="pun">:</span><span class="pln"> </span><span class="lit">30</span></li><li class="L9"><span class="pln">name</span><span class="pun">:</span><span class="pln"> </span><span class="typ">Justin</span><span class="pun">,</span><span class="pln">age</span><span class="pun">:</span><span class="pln"> </span><span class="lit">19</span></li><li class="L0"><span class="pln">&nbsp;</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>在上面的代码中，peopleRDD.map(lambda line : line.split(‘,’))作用是对people这个RDD中的每一行元素都进行解析。比如，people这个RDD的第一行是：</p>
<pre><code>Michael, 29
</code></pre>
<p>这行内容经过peopleRDD.map(lambda line : 
line.split(‘,’)).操作后，就得到一个集合{Michael,29}。后面经过map(lambda attributes : 
Row(attributes[0], 
attributes[1]))操作时，这时的p就是这个集合{Michael,29}，这时p[0]就是Micheael，p[1]就是
29，map(lambda attributes : Row(attributes[0], 
attributes[1]))就会生成一个Row对象，这个对象里面包含了两个字段的值，这个Row对象就构成了rowRDD中的其中一个元素。因为
people有3行文本，所以，最终，rowRDD中会包含3个元素，每个元素都是org.apache.spark.sql.Row类型。实际
上，Row对象只是对基本数据类型（比如整型或字符串）的数组的封装，本质就是一个定长的字段数组。<br>
peopleDF = spark.createDataFrame(rowRDD, 
schema)，这条语句就相当于建立了rowRDD数据集和模式之间的对应关系，从而我们就知道对于rowRDD的每行记录，第一个字段的名称是
schema中的“name”，第二个字段的名称是schema中的“age”。</p>
<h1>把RDD保存成文件</h1>
<p>这里介绍如何把RDD保存成文本文件，后面还会介绍其他格式的保存。</p>
<h2>第1种保存方法</h2>
<p>进入pyspark执行下面命令：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">read</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="str">"json"</span><span class="pun">).</span><span class="pln">load</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/examples/src/main/resources/people.json"</span><span class="pun">)</span></li><li class="L1"><span class="pln">&nbsp;</span></li><li class="L2"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF</span><span class="pun">.</span><span class="pln">select</span><span class="pun">(</span><span class="str">"name"</span><span class="pun">,</span><span class="pln"> </span><span class="str">"age"</span><span class="pun">).</span><span class="pln">write</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="str">"csv"</span><span class="pun">).</span><span class="pln">save</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/mycode/newpeople.csv"</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>可以看出，这里使用select(“name”, “age”)确定要把哪些列进行保存，然后调用write.format(“csv”).save ()保存成csv文件。在后面小节中，我们还会介绍其他保存方式。<br>
另外，write.format()支持输出 json,parquet, jdbc, orc, libsvm, csv, 
text等格式文件，如果要输出文本文件，可以采用write.format(“text”)，但是，需要注意，只有select()中只存在一个列时，
才允许保存成文本文件，如果存在两个列，比如select(“name”, “age”)，就不能保存成文本文件。</p>
<p>上述过程执行结束后，可以打开第二个终端窗口，在Shell命令提示符下查看新生成的newpeople.csv：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd  </span><span class="pln">/usr/local/spark/mycode/</span></li><li class="L1"><span class="pln">ls</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>可以看到/usr/local/spark/mycode/这个目录下面有个newpeople.csv文件夹（注意，不是文件），这个文件夹中包含下面两个文件：</p>
<pre><code>part-r-00000-33184449-cb15-454c-a30f-9bb43faccac1.csv 
_SUCCESS
</code></pre>
<p>不用理会_SUCCESS这个文件，只要看一下part-r-00000-33184449-cb15-454c-a30f-9bb43faccac1.csv这个文件，可以用vim编辑器打开这个文件查看它的内容，该文件内容如下：</p>
<pre><code>Michael,
Andy,30
Justin,19
</code></pre>
<p>因为people.json文件中，Michael这个名字不存在对应的age，所以，上面第一行逗号后面没有内容。<br>
如果我们要再次把newpeople.csv中的数据加载到RDD中，可以直接使用newpeople.csv目录名称，而不需要使用part-r-00000-33184449-cb15-454c-a30f-9bb43faccac1.csv 文件，如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> textFile </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/mycode/newpeople.csv"</span><span class="pun">)</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> textFile</span><span class="pun">.</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L2"><span class="typ">Justin</span><span class="pun">,</span><span class="lit">19</span></li><li class="L3"><span class="typ">Michael</span><span class="pun">,</span></li><li class="L4"><span class="typ">Andy</span><span class="pun">,</span><span class="lit">30</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>第2种保存方法</h2>
<p>进入pyspark执行下面命令：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">read</span><span class="pun">.</span><span class="pln">format</span><span class="pun">(</span><span class="str">"json"</span><span class="pun">).</span><span class="pln">load</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/examples/src/main/resources/people.json"</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> peopleDF</span><span class="pun">.</span><span class="pln">rdd</span><span class="pun">.</span><span class="pln">saveAsTextFile</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/mycode/newpeople.txt"</span><span class="pun">)</span></li><li class="L2"><span class="pln">&nbsp;</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>可以看出，我们是把DataFrame转换成RDD，然后调用saveAsTextFile()保存成文本文件。在后面小节中，我们还会介绍其他保存方式。<br>
上述过程执行结束后，可以打开第二个终端窗口，在Shell命令提示符下查看新生成的newpeople.txt：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd  </span><span class="pln">/usr/local/spark/mycode/</span></li><li class="L1"><span class="pln">ls</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>可以看到/usr/local/spark/mycode/这个目录下面有个newpeople.txt文件夹（注意，不是文件），这个文件夹中包含下面两个文件：</p>
<pre><code>part-00000  
_SUCCESS
</code></pre>
<p>不用理会_SUCCESS这个文件，只要看一下part-00000这个文件，可以用vim编辑器打开这个文件查看它的内容，该文件内容如下：</p>
<pre><code>[null,Michael]
[30,Andy]
[19,Justin]
</code></pre>
<p>如果我们要再次把newpeople.txt中的数据加载到RDD中，可以直接使用newpeople.txt目录名称，而不需要使用part-00000文件，如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> textFile </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">textFile</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/mycode/newpeople.txt"</span><span class="pun">)</span></li><li class="L1"><span class="pun">&gt;&gt;&gt;</span><span class="pln"> textFile</span><span class="pun">.</span><span class="pln">foreach</span><span class="pun">(</span><span class="kwd">print</span><span class="pun">)</span></li><li class="L2"><span class="pun">[</span><span class="pln">null</span><span class="pun">,</span><span class="typ">Michael</span><span class="pun">]</span></li><li class="L3"><span class="pun">[</span><span class="lit">30</span><span class="pun">,</span><span class="typ">Andy</span><span class="pun">]</span></li><li class="L4"><span class="pun">[</span><span class="lit">19</span><span class="pun">,</span><span class="typ">Justin</span><span class="pun">]</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
			</div><!-- .entry-content -->

	<footer class="entry-footer">
		<div class="entry-author">
			<div class="author-title">本文作者</div>
			
		<div class="author-avatar"><img src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/2.jpg" alt="阮榕城" class="avatar avatar-thumbnail wp-user-avatar wp-user-avatar-thumbnail alignnone photo"></div>
		<div class="author-info">
			<p class="author-name"><a href="http://dblab.xmu.edu.cn/blog/author/ruanrongcheng/">阮榕城</a></p>
			<p class="author-desc">磨人的小妖精！</p>
			<p class="author-contact"><a href="http://www.nekomiao.me/" target="_blank" title="个人主页" class="homepage"><i class="fa fa-home"></i>www.nekomiao.me</a><i class="fa fa-envelope"></i><span class="envelope">moc.qq@crnaur</span></p>
		</div>
			</div>
		<div class="entry-info">
			<span class="permalink"><i class="fa fa-external-link"></i> <a href="http://dblab.xmu.edu.cn/blog/1720-2/" title="Spark2.1.0+入门：从RDD转换得到DataFrame(Python版)">http://dblab.xmu.edu.cn/blog/1720-2/</a></span><span class="category"><i class="fa fa-folder-open-o"></i> <a href="http://dblab.xmu.edu.cn/blog/category/big-data/" rel="category tag">大数据</a></span>		</div>
		<div class="yarpp-related yarpp-related-none">
</div>
	</footer><!-- .entry-footer -->
</article><!-- #post-## -->
			</div>
</div><!-- .row -->

	<div class="row">
		<div class="col-sm-3"></div>
		<div class="col-sm-9 site-footer">
			© 2014 <a href="http://dblab.xmu.edu.cn/">厦大数据库实验室</a>
					</div>
	</div>
</div><!-- .container -->
<link rel="stylesheet" id="yarppRelatedCss-css" href="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/related.css" type="text/css" media="all">
<script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.js"></script>
<script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/power.js"></script>
<script type="text/javascript" src="4.4Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9A%E4%BB%8ERDD%E8%BD%AC%E6%8D%A2%E5%BE%97%E5%88%B0DataFrame(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-embed.js"></script>

<div class="back-to-top" id="back-to-top" title="嗖的就上去了！" style="display: block;"><span><i class="fa fa-chevron-up"></i></span></div></body></html>