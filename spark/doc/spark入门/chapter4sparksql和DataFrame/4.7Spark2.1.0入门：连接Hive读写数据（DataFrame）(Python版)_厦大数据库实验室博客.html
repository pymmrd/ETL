<!DOCTYPE html>
<html lang="zh-CN"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Spark2.1.0入门：连接Hive读写数据（DataFrame）(Python版)_厦大数据库实验室博客</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="renderer" content="webkit">
<link rel="dns-prefetch" href="http://cdn.staticfile.org/">
<link rel="dns-prefetch" href="http://s.w.org/">
<link rel="stylesheet" id="yarppWidgetCss-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/widget.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-quicklatex-format-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/quicklatex-format.css" type="text/css" media="all">
<link rel="stylesheet" id="bootstrap-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/bootstrap.css" type="text/css" media="all">
<link rel="stylesheet" id="font-awesome-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/font-awesome.css" type="text/css" media="all">
<link rel="stylesheet" id="power-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/style.css" type="text/css" media="all">
<link rel="stylesheet" id="google-code-prettify-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.css" type="text/css" media="all">
<script type="text/javascript" async="" charset="utf-8" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/core.js"></script><script src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/hm.js"></script><script src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/z_stat.js"></script><script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery_002.js"></script>
<script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery.js"></script>
<script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery-migrate.js"></script>
<script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-quicklatex-frontend.js"></script>
<link rel="https://api.w.org/" href="http://dblab.xmu.edu.cn/blog/wp-json/">
<link rel="prev" title="Python：字典" href="http://dblab.xmu.edu.cn/blog/1728-2/">
<link rel="next" title="Python：条件语句" href="http://dblab.xmu.edu.cn/blog/1731-2/">
<link rel="canonical" href="http://dblab.xmu.edu.cn/blog/1729-2/">
<link rel="alternate" type="application/json+oembed" href="http://dblab.xmu.edu.cn/blog/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fdblab.xmu.edu.cn%2Fblog%2F1729-2%2F">
<!--[if lt IE 9]>
<script src="http://dblab.xmu.edu.cn/blog/wp-content/themes/power/js/html5shiv.js"></script>
<![endif]-->
</head>

<body class="post-template-default single single-post postid-1729 single-format-standard group-blog">
<div class="container site-page">

<div class="row">
	<div class="col-sm-3 site-infos">
		<h4 class="site-title">
			<a href="http://dblab.xmu.edu.cn/blog/" title="厦大数据库实验室博客" rel="home">厦大数据库实验室博客</a>
		</h4>
		<div class="site-description">总结、分享、收获<p><a href="http://dblab.xmu.edu.cn/" title="厦大数据库实验室">实验室主页</a></p></div>

		<nav class="main-navigation" role="navigation">
			<div class="menu-primary-container"><ul id="menu-primary" class="menu menu-level-1"><li id="menu-item-80" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/">首页</a></li>
<li id="menu-item-85" class="menu-item item-level-1 current-path"><a href="http://dblab.xmu.edu.cn/blog/category/big-data/">大数据</a></li>
<li id="menu-item-676" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/databases/">数据库</a></li>
<li id="menu-item-87" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/data-mining/">数据挖掘</a></li>
<li id="menu-item-86" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/others/">其他</a></li>
</ul></div>		</nav><!-- #site-navigation -->

		<div class="search"><form role="search" method="get" class="search-form" action="http://dblab.xmu.edu.cn/blog/">
				<label>
					<span class="screen-reader-text">搜索：</span>
					<input class="search-field" placeholder="搜索…" name="s" type="search">
				</label>
				<input class="search-submit" value="搜索" type="submit">
			</form></div>
	</div>
	<div class="col-sm-9 site-main">

					<article id="post-1729" class="post-1729 post type-post status-publish format-standard hentry category-big-data">
	<header class="entry-header">
		<h1 class="entry-title">Spark2.1.0入门：连接Hive读写数据（DataFrame）(Python版)</h1>

		<div class="entry-meta">
			<span class="author"><i class="fa fa-user"></i> 阮榕城</span><span class="date"><i class="fa fa-calendar"></i> <time datetime="2017-12-08T11:10:59+00:00">2017年12月8日</time> <span class="updated">(updated: <time class="updated" datetime="2017-12-19T21:22:39+00:00">2017年12月19日</time>)</span></span><span class="views" id="views"><i class="fa fa-eye"></i> 4516</span>		</div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div class="entry-content">
		<div class="bigdata-book">
			<a href="http://dblab.xmu.edu.cn/post/5899/" title="2019年1月20日寒假大数据师资培训班" target="_blank"><img src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/peixunban2019-01-20.jpg" alt="2019年1月20日寒假大数据师资培训班"></a>
		</div>
		<p>【版权声明】博客内容由厦门大学数据库实验室拥有版权，未经允许，请勿转载！<br>
<a href="http://dblab.xmu.edu.cn/blog/1709-2/" target="_blank">返回Spark教程首页</a></p>
<p>Hive是基于Hadoop的数据仓库（要想了解更多数据仓库Hive的知识以及如何安装Hive，可以参考厦门大学数据库实验室的<a href="http://dblab.xmu.edu.cn/post/bigdata-online-course/#lesson8" target="_blank">Hive授课视频</a>、<a href="http://dblab.xmu.edu.cn/blog/install-hive/" target="_blank">Hive安装指南</a>）。本节内容介绍Spark如何连接Hive并读写数据。</p>
<p><span id="more-1729"></span></p>
<h1>一、让Spark包含Hive支持</h1>
<p>为了让Spark能够访问Hive，必须为Spark添加Hive支持。Spark官方提供的预编译版本，通常是不包含Hive支持的，需要采用源码编译，编译得到一个包含Hive支持的Spark版本，然后采用我们之前在“<a href="http://dblab.xmu.edu.cn/blog/931-2/" target="_blank">Spark安装和使用</a>”部分介绍的方法安装Spark。</p>
<h2>测试一下电脑上已经安装的Spark版本是否支持Hive</h2>
<p>现在让我们测试一下自己电脑上已经安装的Spark版本是否支持Hive。请请登录Linux系统，打开一个终端，然后，执行下面命令：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/spark</span></li><li class="L1"><span class="pln">./bin/pyspark</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>这样就启动进入了spark-shell，然后在scala命令提示符下输入：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">scala</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">import</span><span class="pln"> org</span><span class="pun">.</span><span class="pln">apache</span><span class="pun">.</span><span class="pln">spark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">hive</span><span class="pun">.</span><span class="typ">HiveContext</span></li><li class="L1"><span class="pun">&lt;</span><span class="pln">console</span><span class="pun">&gt;:</span><span class="lit">25</span><span class="pun">:</span><span class="pln"> error</span><span class="pun">:</span><span class="pln"> object hive </span><span class="kwd">is</span><span class="pln"> </span><span class="kwd">not</span><span class="pln"> a member of package org</span><span class="pun">.</span><span class="pln">apache</span><span class="pun">.</span><span class="pln">spark</span><span class="pun">.</span><span class="pln">sql</span></li><li class="L2"><span class="pln">         </span><span class="kwd">import</span><span class="pln"> org</span><span class="pun">.</span><span class="pln">apache</span><span class="pun">.</span><span class="pln">spark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">hive</span><span class="pun">.</span><span class="typ">HiveContext</span></li><li class="L3"><span class="pln">                                     </span><span class="pun">^</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>看到了吧，会返回错误信息，也就是spark无法识别org.apache.spark.sql.hive.HiveContext，这就说明你当前电脑上的Spark版本不包含Hive支持。</p>
<p>如果你当前电脑上的Spark版本包含Hive支持，那么应该显示下面的正确信息：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">scala</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">import</span><span class="pln"> org</span><span class="pun">.</span><span class="pln">apache</span><span class="pun">.</span><span class="pln">spark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">hive</span><span class="pun">.</span><span class="typ">HiveContext</span></li><li class="L1"><span class="kwd">import</span><span class="pln"> org</span><span class="pun">.</span><span class="pln">apache</span><span class="pun">.</span><span class="pln">spark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">hive</span><span class="pun">.</span><span class="typ">HiveContext</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<h2>采用源码编译方法得到支持Hive的Spark版本</h2>
<p>经过上面测试，如果你当前电脑上的Spark版本包含Hive支持，那就可以不用进行下面的源码编译步骤。如果你当前电脑上的Spark版本不包含Hive支持，请根据下面教程编译一个包含Hive支持的Spark版本。<br>
（备注：笔者已经把我们实验室编译成功的spark-2.1.0-bin-h27hive.tgz文件上传到了百度云盘（文件大小170MB，<a href="http://pan.baidu.com/s/1nv8Y2hj" target="_blank">下载地址</a>），所以，你或者可以按照下面的方法自己编译，或者可以直接下载我们已经编译成功的版本）<br>
请登录Linux系统，打开一个火狐（Firefox）浏览器。在Linux系统的火狐浏览器中，<a href="http://spark.apache.org/downloads.html" target="_blank">请点击这里访问Spark官网</a>下载Spark源码版本（或者直接把下载地址复制到火狐浏览器中打开官网，下载地址是http://spark.apache.org/downloads.html）。<br>
进入这个官网后，可以按照下图配置选择“2.1.0(Dec 28, 2016)”和“SourceCode”，然后，在图中红色方框内，有个“Download Spark: spark-2.1.0.tgz”的下载链接，点击该链接就可以下载Spark源码文件了。<br>
<img src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/spark2.png" alt=""><br>
如果是在火狐浏览器中下载spark-2.1.0.tgz，这个文件被默认放置在你当前用户的下载目录下，我们教程是统一使用hadoop用户登录Linux系统，所以，下载文件被放到了“/home/hadoop/下载”这个目录下。<br>
由于带有中文名称的目录在进行打包编译时，往往容易出现错误，为了保险起见，我们还是把这个文件解压缩到一个英文目录下。请在Linux系统中打开一个终端，然后执行下面命令进行文件解压：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/home/hadoop/下载  //spark-2.1.0.tgz就在这个目录下面</span></li><li class="L1"><span class="kwd">ls </span><span class="com">#可以看到刚才下载的spark-2.1.0.tgz文件</span></li><li class="L2"><span class="kwd">sudo tar </span><span class="pln">-zxf ./spark-2.1.0.tgz -C /home/hadoop/</span></li><li class="L3"><span class="kwd">cd </span><span class="pln">/home/hadoop</span></li><li class="L4"><span class="kwd">ls </span><span class="com">#这时可以看到解压得到的文件夹spark-2.1.0</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>下面很关键，我们要进行源码编译，并且在编译命令中设置一些选项，从而让Spark支持Hive。<br>
在编译时，需要给出你电脑上之前已经安装好的Hadoop的版本。如何查询Hadoop版本号呢？请使用下面命令查询：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">hadoop version</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>运行上面命令后，就会显示Hadoop版本信息。笔者电脑上的Hadoop版本信息是2.7.1。<br>
下面，就可以运行编译命令，对Spark源码进行编译，让它支持Hive，命令如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/home/hadoop/spark-2.1.0</span></li><li class="L1"><span class="pln">./dev/make-distribution.sh —tgz —name h27hive -Pyarn -Phadoop-2.7 -Dhadoop.version=2.7.1 -Phive -Phive-thriftserver -DskipTests</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>其中，-Phadoop-2.7 -Dhadoop.version=2.7.1 
指定安装spark时的hadoop版本，一定要对应，这个hadoop版本是你当前电脑上已经安装的Hadoop的版本。 -Phive 
-Phive-thriftserver这两个选项让其支持Hive。 -DskipTests能避免测试不通过时发生的错误。</p>
<p>上面命令中“h27hive”只是我们给编译以后的文件的一个名称，最终编译成功后会得到文件名“spark-2.1.0-bin-h27hive.tgz”，这个就是包含Hive支持的Spark安装文件。<br>
上述编译命令运行时间，根据电脑和网络情况，耗费的时间不一样，笔者实验室电脑编译了3个多小时，网络上其他用户有的也编译了几个小时，而且中间编译过程
还会发生网络故障导致编译失败，那就只能重新编译。总之，这个过程有点痛苦，笔者为了编译一个支持Hive的Spark版本，也是耗费了10几个小时。编
译成功以后，就可以得到一个文件名为“spark-2.1.0-bin-h27hive.tgz”的文件，这个就是包含Hive支持的Spark安装文
件，然后我们就可以参考前面章节讲过的<a href="http://dblab.xmu.edu.cn/blog/931-2/" target="_blank">Spark安装方法</a>开始安装这个支持Hive的Spark版本。</p>
<h2>安装支持Hive的Spark版本</h2>
<p>本教程目标是“零门槛零障碍”学习Spark知识，所以，下面给出安装的过程。<br>
为了让大家可以顺利安装支持Hive的Spark版本，笔者已经把我们实验室编译成功的spark-2.1.0-bin-h27hive.tgz文件上传到了百度云盘（文件大小170MB，<a href="http://pan.baidu.com/s/1nv8Y2hj" target="_blank">下载地址</a>），
所以，你或者可以自己编译，或者可以直接下载我们已经编译成功的版本。不管是自己编译的，还是从百度云盘下载的，我们这里都假设这个支持Hive的
Spark安装文件都被保存在了“/home/hadoop/下载/spark-2.1.0-bin-h27hive.tgz”。而且，需要重点强调的
是，根据我们的教程，我们在此前的Spark安装章节已经在电脑上安装了一个Spark版本（不支持Hive），当时的安装目录是“/usr/local
/spark”。我们不需要卸载以前这个已经安装成功的Spark版本（不支持Hive），只需要把新的Spark版本（包含Hive支持）安装在另外一
个名字为sparkwithhive的目录下即可。而且，安装成功以后，可以分别打开两个终端窗口，第一个终端窗口中启动spark-shell（不支持
Hive），同时在第二个终端窗口中启动spark-shell（包含Hive支持），二者可以同时运行。<br>
好的，下面就开始安装新的Spark版本（包含Hive支持），命令如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/home/hadoop/下载/</span></li><li class="L1"><span class="kwd">sudo tar </span><span class="pln">-zxf ~/下载/spark-2.1.0-bin-h27hive.tgz -C /usr/local</span></li><li class="L2"><span class="com">#执行上面的解压缩命令时需要你输入当前登录用户的登录密码</span></li><li class="L3"><span class="kwd">cd </span><span class="pln">/usr/local</span></li><li class="L4"><span class="kwd">sudo mv </span><span class="pln">./spark-2.1.0-bin-h27hive ./sparkwithhive</span></li><li class="L5"><span class="kwd">sudo chown </span><span class="pln">-R hadoop:hadoop ./sparkwithhive</span></li><li class="L6"><span class="kwd">cd </span><span class="pln">/usr/local/sparkwithhive/</span></li><li class="L7"><span class="kwd">cp </span><span class="pln">./conf/spark-env.sh.template ./conf/spark-env.sh</span></li><li class="L8"><span class="kwd">vim </span><span class="pln">./conf/spark-env.sh</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>上面用vim编辑器打开了spark-env.sh文件，请在这个文件的开头第一行增加一行如下内容：</p>
<pre><code>export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)
</code></pre>
<p>然后，保存文件，退出vim编辑器，继续执行下面命令：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/spark</span></li><li class="L1"><span class="kwd">cd </span><span class="pln">/usr/local/sparkwithhive</span></li><li class="L2"><span class="com">#下面运行一个样例程序，测试是否成功安装</span></li><li class="L3"><span class="pln">bin/run-example SparkPi 2&gt;&amp;1 | grep </span><span class="str">"Pi is"</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>如果能够得到下面信息，就说明成功了。</p>
<pre><code>Pi is roughly 3.146315731578658
</code></pre>
<p>为了让Spark能够访问Hive，需要把Hive的配置文件hive-site.xml拷贝到Spark的conf目录下，请在Shell命令提示符状态下操作：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/sparkwithhive/conf</span></li><li class="L1"><span class="kwd">cp </span><span class="pln">/usr/local/hive/conf/hive-site.xml .</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>然后，就可以启动进入pyspark，命令如下：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/sparkwithhive</span></li><li class="L1"><span class="pln">./bin/pyspark</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>请输入下面语句：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">HiveContext</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>如果没有提示错误，就说明你当前启动的Spark版本可以支持Hive，恭喜你，可以进行下面的Hive数据读写实验了。</p>
<h1>二、在Hive中创建数据库和表</h1>
<p>假设目前你已经根据厦门大学数据库实验室的Hive安装指南（要想了解更多数据仓库Hive的知识以及如何安装Hive，可以参考厦门大学数据库实验室的<a href="http://dblab.xmu.edu.cn/post/bigdata-online-course/#lesson8" target="_blank">Hive授课视频</a>、<a href="http://dblab.xmu.edu.cn/blog/install-hive/" target="_blank">Hive安装指南</a>），完成了Hive的安装，并且使用的是MySQL数据库来存放Hive的元数据。<br>
下面，请登录Linux系统（本教程统一采用hadoop用户名登录），打开一个终端，进入Shell命令提示符状态。因为需要借助于MySQL保存Hive的元数据，所以，请首先启动MySQL数据库：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">service mysql start  </span><span class="com">#可以在Linux的任何目录下执行该命令</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>由于Hive是基于Hadoop的数据仓库，使用HiveQL语言撰写的查询语句，最终都会被Hive自动解析成MapReduce任务由Hadoop去具体执行，因此，需要启动Hadoop，然后再启动Hive。<br>
然后执行以下命令启动Hadoop：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/hadoop</span></li><li class="L1"><span class="pln">./sbin/start-all.sh</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>Hadoop启动成功以后，可以再启动Hive:</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/hive</span></li><li class="L1"><span class="pln">./bin/hive  </span><span class="com">#由于已经配置了path环境变量，这里也可以直接使用hive，不加路径</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>通过上述过程，我们就完成了MySQL、Hadoop和Hive三者的启动。</p>
<p>下面我们进入Hive，新建一个数据库sparktest，并在这个数据库下面创建一个表student，并录入两条数据。<br>
下面操作请在Hive命令提示符下操作：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-hive prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> create database </span><span class="kwd">if</span><span class="pln"> </span><span class="kwd">not</span><span class="pln"> exists sparktest</span><span class="pun">;</span><span class="com">//创建数据库sparktest</span></li><li class="L1"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> show databases</span><span class="pun">;</span><span class="pln"> </span><span class="com">//显示一下是否创建出了sparktest数据库</span></li><li class="L2"><span class="com">//下面在数据库sparktest中创建一个表student</span></li><li class="L3"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> create table </span><span class="kwd">if</span><span class="pln"> </span><span class="kwd">not</span><span class="pln"> exists sparktest</span><span class="pun">.</span><span class="pln">student</span><span class="pun">(</span></li><li class="L4"><span class="pun">&gt;</span><span class="pln"> id </span><span class="kwd">int</span><span class="pun">,</span></li><li class="L5"><span class="pun">&gt;</span><span class="pln"> name </span><span class="kwd">string</span><span class="pun">,</span></li><li class="L6"><span class="pun">&gt;</span><span class="pln"> gender </span><span class="kwd">string</span><span class="pun">,</span></li><li class="L7"><span class="pun">&gt;</span><span class="pln"> age </span><span class="kwd">int</span><span class="pun">);</span></li><li class="L8"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> alter table student change id id </span><span class="kwd">int</span><span class="pln"> auto_increment primary key</span><span class="pun">;</span></li><li class="L9"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">use</span><span class="pln"> sparktest</span><span class="pun">;</span><span class="pln"> </span><span class="com">//切换到sparktest</span></li><li class="L0"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> show tables</span><span class="pun">;</span><span class="pln"> </span><span class="com">//显示sparktest数据库下面有哪些表</span></li><li class="L1"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> insert </span><span class="kwd">into</span><span class="pln"> student values</span><span class="pun">(</span><span class="lit">1</span><span class="pun">,</span><span class="str">'Xueqian'</span><span class="pun">,</span><span class="str">'F'</span><span class="pun">,</span><span class="lit">23</span><span class="pun">);</span><span class="pln"> </span><span class="com">//插入一条记录</span></li><li class="L2"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> insert </span><span class="kwd">into</span><span class="pln"> student values</span><span class="pun">(</span><span class="lit">2</span><span class="pun">,</span><span class="str">'Weiliang'</span><span class="pun">,</span><span class="str">'M'</span><span class="pun">,</span><span class="lit">24</span><span class="pun">);</span><span class="pln"> </span><span class="com">//再插入一条记录</span></li><li class="L3"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">select</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="kwd">from</span><span class="pln"> student</span><span class="pun">;</span><span class="pln"> </span><span class="com">//显示student表中的记录</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">hive</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>通过上面操作，我们就在Hive中创建了sparktest.student表，这个表有两条数据。</p>
<h1>三、连接Hive读写数据</h1>
<p>现在我们看如何使用Spark读写Hive中的数据。注意，操作到这里之前，你一定已经按照前面的各个操作步骤，启动了Hadoop、Hive、MySQL和pyspark（包含Hive支持）。<br>
在进行编程之前，我们需要做一些准备工作，我们需要修改“/usr/local/sparkwithhive/conf/spark-env.sh”这个配置文件：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/sparkwithhive/conf/</span></li><li class="L1"><span class="kwd">vim </span><span class="pln">spark-env.sh</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>这样就使用vim编辑器打开了spark-env.sh这个文件，这文件里面以前可能包含一些配置信息，全部删除，然后输入下面内容：</p>
<pre><code>export JAVA_HOME=/usr/lib/jvm/default-java
export CLASSPATH=$CLASSPATH:/usr/local/hive/lib
export SCALA_HOME=/usr/local/scala
export HADOOP_CONF_DIR=/usr/local/hadoop/etc/hadoop
export HIVE_CONF_DIR=/usr/local/hive/conf
export SPARK_CLASSPATH=$SPARK_CLASSPATH:/usr/local/hive/lib/mysql-connector-java-5.1.40-bin.jar
</code></pre>
<p>保存spark-env.sh这个文件，退出vim编辑器。</p>
<p>好了，经过了前面如此漫长的准备过程，现在终于可以编写调试Spark连接Hive读写数据的代码了。<br>
下面，请在pyspark（包含Hive支持）中执行以下命令从Hive中读取数据：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">HiveContext</span></li><li class="L1"><span class="pln">hive_context </span><span class="pun">=</span><span class="pln"> </span><span class="typ">HiveContext</span><span class="pun">(</span><span class="pln">sc</span><span class="pun">)</span></li><li class="L2"><span class="pln">hive_context</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">(</span><span class="str">'use sparktest'</span><span class="pun">)</span></li><li class="L3"><span class="pln">hive_context</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">(</span><span class="str">'select * from student'</span><span class="pun">).</span><span class="pln">show</span><span class="pun">()</span></li><li class="L4"><span class="pln">&nbsp;</span></li><li class="L5"><span class="pun">+---+--------+------+---+</span></li><li class="L6"><span class="pun">|</span><span class="pln"> id</span><span class="pun">|</span><span class="pln">    name</span><span class="pun">|</span><span class="pln">gender</span><span class="pun">|</span><span class="pln">age</span><span class="pun">|</span></li><li class="L7"><span class="pun">+---+--------+------+---+</span></li><li class="L8"><span class="pun">|</span><span class="pln">  </span><span class="lit">1</span><span class="pun">|</span><span class="pln"> </span><span class="typ">Xueqian</span><span class="pun">|</span><span class="pln">     F</span><span class="pun">|</span><span class="pln"> </span><span class="lit">23</span><span class="pun">|</span></li><li class="L9"><span class="pun">|</span><span class="pln">  </span><span class="lit">2</span><span class="pun">|</span><span class="typ">Weiliang</span><span class="pun">|</span><span class="pln">     M</span><span class="pun">|</span><span class="pln"> </span><span class="lit">24</span><span class="pun">|</span></li><li class="L0"><span class="pun">+---+--------+------+---+</span></li><li class="L1"><span class="pln">&nbsp;</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>下面，请在spark-shell（包含Hive支持）中执行以下命令向Hive中写入数据。为了对比插入数据前后Hive中的数据变化，首先，请打开一个终端窗口，启动Hive：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/hive</span></li><li class="L1"><span class="pln">./bin/hive</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>启动后就进入了hive命令提示符状态，然后输入如下命令查看sparktest.student表中的数据：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-hive prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">use</span><span class="pln"> sparktest</span><span class="pun">;</span></li><li class="L1"><span class="pln">OK</span></li><li class="L2"><span class="typ">Time</span><span class="pln"> taken</span><span class="pun">:</span><span class="pln"> </span><span class="lit">0.016</span><span class="pln"> seconds</span></li><li class="L3"><span class="pln">&nbsp;</span></li><li class="L4"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">select</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="kwd">from</span><span class="pln"> student</span><span class="pun">;</span></li><li class="L5"><span class="pln">OK</span></li><li class="L6"><span class="lit">1</span><span class="pln">   </span><span class="typ">Xueqian</span><span class="pln"> F   </span><span class="lit">23</span></li><li class="L7"><span class="lit">2</span><span class="pln">   </span><span class="typ">Weiliang</span><span class="pln">    M   </span><span class="lit">24</span></li><li class="L8"><span class="typ">Time</span><span class="pln"> taken</span><span class="pun">:</span><span class="pln"> </span><span class="lit">0.05</span><span class="pln"> seconds</span><span class="pun">,</span><span class="pln"> </span><span class="typ">Fetched</span><span class="pun">:</span><span class="pln"> </span><span class="lit">2</span><span class="pln"> row</span><span class="pun">(</span><span class="pln">s</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">hive</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>下面，我们编写程序向Hive数据库的sparktest.student表中插入两条数据，请切换到spark-shell（含Hive支持）终端窗口，输入以下命令：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-hive prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">Row</span></li><li class="L1"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StructType</span></li><li class="L2"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StructField</span></li><li class="L3"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StringType</span></li><li class="L4"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">.</span><span class="pln">types </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">IntegerType</span></li><li class="L5"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">sql </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">HiveContext</span></li><li class="L6"><span class="pln">hive_context </span><span class="pun">=</span><span class="pln"> </span><span class="typ">HiveContext</span><span class="pun">(</span><span class="pln">sc</span><span class="pun">)</span></li><li class="L7"><span class="pln">hive_context</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">(</span><span class="str">'use sparktest'</span><span class="pun">)</span></li><li class="L8"><span class="pln">studentRDD </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">sparkContext</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">([</span><span class="str">"3 Rongcheng M 26"</span><span class="pun">,</span><span class="str">"4 Guanhua M 27"</span><span class="pun">]).</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> line </span><span class="pun">:</span><span class="pln"> line</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">" "</span><span class="pun">))</span></li><li class="L9"><span class="pln">schema </span><span class="pun">=</span><span class="pln"> </span><span class="typ">StructType</span><span class="pun">([</span><span class="typ">StructField</span><span class="pun">(</span><span class="str">"name"</span><span class="pun">,</span><span class="pln"> </span><span class="typ">StringType</span><span class="pun">(),</span><span class="pln"> </span><span class="kwd">True</span><span class="pun">),</span><span class="typ">StructField</span><span class="pun">(</span><span class="str">"gender"</span><span class="pun">,</span><span class="pln"> </span><span class="typ">StringType</span><span class="pun">(),</span><span class="pln"> </span><span class="kwd">True</span><span class="pun">),</span><span class="typ">StructField</span><span class="pun">(</span><span class="str">"age"</span><span class="pun">,</span><span class="typ">IntegerType</span><span class="pun">(),</span><span class="pln"> </span><span class="kwd">True</span><span class="pun">)])</span></li><li class="L0"><span class="pln">rowRDD </span><span class="pun">=</span><span class="pln"> studentRDD</span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> p </span><span class="pun">:</span><span class="pln"> </span><span class="typ">Row</span><span class="pun">(</span><span class="pln">p</span><span class="pun">[</span><span class="lit">1</span><span class="pun">].</span><span class="pln">strip</span><span class="pun">(),</span><span class="pln"> p</span><span class="pun">[</span><span class="lit">2</span><span class="pun">].</span><span class="pln">strip</span><span class="pun">(),</span><span class="kwd">int</span><span class="pun">(</span><span class="pln">p</span><span class="pun">[</span><span class="lit">3</span><span class="pun">])))</span></li><li class="L1"><span class="com">//建立起Row对象和模式之间的对应关系，也就是把数据和模式对应起来</span></li><li class="L2"><span class="pln">studentDF </span><span class="pun">=</span><span class="pln"> spark</span><span class="pun">.</span><span class="pln">createDataFrame</span><span class="pun">(</span><span class="pln">rowRDD</span><span class="pun">,</span><span class="pln"> schema</span><span class="pun">)</span></li><li class="L3"><span class="pln">studentDF</span><span class="pun">.</span><span class="pln">registerTempTable</span><span class="pun">(</span><span class="str">"tempTable"</span><span class="pun">)</span></li><li class="L4"><span class="pln">hive_context</span><span class="pun">.</span><span class="pln">sql</span><span class="pun">(</span><span class="str">'insert into student select * from tempTable'</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">hive</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>然后，请切换到刚才的hive终端窗口，输入以下命令查看Hive数据库内容的变化：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-hive prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">hive</span><span class="pun">&gt;</span><span class="pln"> </span><span class="kwd">select</span><span class="pln"> </span><span class="pun">*</span><span class="pln"> </span><span class="kwd">from</span><span class="pln"> student</span><span class="pun">;</span></li><li class="L1"><span class="pln">OK</span></li><li class="L2"><span class="lit">1</span><span class="pln">   </span><span class="typ">Xueqian</span><span class="pln"> F   </span><span class="lit">23</span></li><li class="L3"><span class="lit">2</span><span class="pln">   </span><span class="typ">Weiliang</span><span class="pln">    M   </span><span class="lit">24</span></li><li class="L4"><span class="lit">3</span><span class="pln">   </span><span class="typ">Rongcheng</span><span class="pln">   M   </span><span class="lit">26</span></li><li class="L5"><span class="lit">4</span><span class="pln">   </span><span class="typ">Guanhua</span><span class="pln"> M   </span><span class="lit">27</span></li><li class="L6"><span class="typ">Time</span><span class="pln"> taken</span><span class="pun">:</span><span class="pln"> </span><span class="lit">0.049</span><span class="pln"> seconds</span><span class="pun">,</span><span class="pln"> </span><span class="typ">Fetched</span><span class="pun">:</span><span class="pln"> </span><span class="lit">4</span><span class="pln"> row</span><span class="pun">(</span><span class="pln">s</span><span class="pun">)</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">hive</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>可以看到，插入数据操作执行成功了!</p>
<p>最后，本节内容我们安装了包含Hive支持的Spark版本，只要用在本节练习中就可以了，本节内容结束后，就不要再去碰/usr/local
/sparkwithhive这个目录了，也就是不要再使用这个支持Hive的版本了（除非其他地方还有用到需要支持Hive的情形）。在其他章节中，我
们还是使用原来不包含Hive支持的Spark版本，也就是目录/usr/local/spark目录下的Spark版本。</p>
			</div><!-- .entry-content -->

	<footer class="entry-footer">
		<div class="entry-author">
			<div class="author-title">本文作者</div>
			
		<div class="author-avatar"><img src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/2.jpg" alt="阮榕城" class="avatar avatar-thumbnail wp-user-avatar wp-user-avatar-thumbnail alignnone photo"></div>
		<div class="author-info">
			<p class="author-name"><a href="http://dblab.xmu.edu.cn/blog/author/ruanrongcheng/">阮榕城</a></p>
			<p class="author-desc">磨人的小妖精！</p>
			<p class="author-contact"><a href="http://www.nekomiao.me/" target="_blank" title="个人主页" class="homepage"><i class="fa fa-home"></i>www.nekomiao.me</a><i class="fa fa-envelope"></i><span class="envelope">moc.qq@crnaur</span></p>
		</div>
			</div>
		<div class="entry-info">
			<span class="permalink"><i class="fa fa-external-link"></i> <a href="http://dblab.xmu.edu.cn/blog/1729-2/" title="Spark2.1.0入门：连接Hive读写数据（DataFrame）(Python版)">http://dblab.xmu.edu.cn/blog/1729-2/</a></span><span class="category"><i class="fa fa-folder-open-o"></i> <a href="http://dblab.xmu.edu.cn/blog/category/big-data/" rel="category tag">大数据</a></span>		</div>
		<div class="yarpp-related yarpp-related-none">
</div>
	</footer><!-- .entry-footer -->
</article><!-- #post-## -->
			</div>
</div><!-- .row -->

	<div class="row">
		<div class="col-sm-3"></div>
		<div class="col-sm-9 site-footer">
			© 2014 <a href="http://dblab.xmu.edu.cn/">厦大数据库实验室</a>
					</div>
	</div>
</div><!-- .container -->
<link rel="stylesheet" id="yarppRelatedCss-css" href="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/related.css" type="text/css" media="all">
<script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.js"></script>
<script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/power.js"></script>
<script type="text/javascript" src="4.7Spark2.1.0%E5%85%A5%E9%97%A8%EF%BC%9A%E8%BF%9E%E6%8E%A5Hive%E8%AF%BB%E5%86%99%E6%95%B0%E6%8D%AE%EF%BC%88DataFrame%EF%BC%89(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-embed.js"></script>

<div class="back-to-top" id="back-to-top" title="嗖的就上去了！" style="display: block;"><span><i class="fa fa-chevron-up"></i></span></div></body></html>