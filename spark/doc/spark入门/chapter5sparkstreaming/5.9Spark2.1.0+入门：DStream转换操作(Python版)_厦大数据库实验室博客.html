<!DOCTYPE html>
<html lang="zh-CN"><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Spark2.1.0+入门：DStream转换操作(Python版)_厦大数据库实验室博客</title>
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="renderer" content="webkit">
<link rel="dns-prefetch" href="http://cdn.staticfile.org/">
<link rel="dns-prefetch" href="http://s.w.org/">
<link rel="stylesheet" id="yarppWidgetCss-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/widget.css" type="text/css" media="all">
<link rel="stylesheet" id="wp-quicklatex-format-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/quicklatex-format.css" type="text/css" media="all">
<link rel="stylesheet" id="bootstrap-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/bootstrap.css" type="text/css" media="all">
<link rel="stylesheet" id="font-awesome-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/font-awesome.css" type="text/css" media="all">
<link rel="stylesheet" id="power-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/style.css" type="text/css" media="all">
<link rel="stylesheet" id="google-code-prettify-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.css" type="text/css" media="all">
<script type="text/javascript" async="" charset="utf-8" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/core.js"></script><script src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/hm.js"></script><script src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/z_stat.js"></script><script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery_002.js"></script>
<script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery.js"></script>
<script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/jquery-migrate.js"></script>
<script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-quicklatex-frontend.js"></script>
<link rel="https://api.w.org/" href="http://dblab.xmu.edu.cn/blog/wp-json/">
<link rel="prev" title="Python：迭代器和生成器" href="http://dblab.xmu.edu.cn/blog/1746-2/">
<link rel="next" title="Spark入门：DStream输出操作(Python版)" href="http://dblab.xmu.edu.cn/blog/1749-2/">
<link rel="canonical" href="http://dblab.xmu.edu.cn/blog/1747-2/">
<link rel="alternate" type="application/json+oembed" href="http://dblab.xmu.edu.cn/blog/wp-json/oembed/1.0/embed?url=http%3A%2F%2Fdblab.xmu.edu.cn%2Fblog%2F1747-2%2F">
<!--[if lt IE 9]>
<script src="http://dblab.xmu.edu.cn/blog/wp-content/themes/power/js/html5shiv.js"></script>
<![endif]-->
</head>

<body class="post-template-default single single-post postid-1747 single-format-standard group-blog">
<div class="container site-page">

<div class="row">
	<div class="col-sm-3 site-infos">
		<h4 class="site-title">
			<a href="http://dblab.xmu.edu.cn/blog/" title="厦大数据库实验室博客" rel="home">厦大数据库实验室博客</a>
		</h4>
		<div class="site-description">总结、分享、收获<p><a href="http://dblab.xmu.edu.cn/" title="厦大数据库实验室">实验室主页</a></p></div>

		<nav class="main-navigation" role="navigation">
			<div class="menu-primary-container"><ul id="menu-primary" class="menu menu-level-1"><li id="menu-item-80" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/">首页</a></li>
<li id="menu-item-85" class="menu-item item-level-1 current-path"><a href="http://dblab.xmu.edu.cn/blog/category/big-data/">大数据</a></li>
<li id="menu-item-676" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/databases/">数据库</a></li>
<li id="menu-item-87" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/data-mining/">数据挖掘</a></li>
<li id="menu-item-86" class="menu-item item-level-1"><a href="http://dblab.xmu.edu.cn/blog/category/others/">其他</a></li>
</ul></div>		</nav><!-- #site-navigation -->

		<div class="search"><form role="search" method="get" class="search-form" action="http://dblab.xmu.edu.cn/blog/">
				<label>
					<span class="screen-reader-text">搜索：</span>
					<input class="search-field" placeholder="搜索…" name="s" type="search">
				</label>
				<input class="search-submit" value="搜索" type="submit">
			</form></div>
	</div>
	<div class="col-sm-9 site-main">

					<article id="post-1747" class="post-1747 post type-post status-publish format-standard hentry category-big-data">
	<header class="entry-header">
		<h1 class="entry-title">Spark2.1.0+入门：DStream转换操作(Python版)</h1>

		<div class="entry-meta">
			<span class="author"><i class="fa fa-user"></i> 阮榕城</span><span class="date"><i class="fa fa-calendar"></i> <time datetime="2017-12-13T10:28:22+00:00">2017年12月13日</time></span><span class="views" id="views"><i class="fa fa-eye"></i> 1249</span>		</div><!-- .entry-meta -->
	</header><!-- .entry-header -->

	<div class="entry-content">
		<div class="bigdata-book">
			<a href="http://dblab.xmu.edu.cn/post/5899/" title="2019年1月20日寒假大数据师资培训班" target="_blank"><img src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/peixunban2019-01-20.jpg" alt="2019年1月20日寒假大数据师资培训班"></a>
		</div>
		<p>【版权声明】博客内容由厦门大学数据库实验室拥有版权，未经允许，请勿转载！<br>
<a href="http://dblab.xmu.edu.cn/blog/1709-2/" target="_blank">返回Spark教程首页</a></p>
<p>DStream转换操作包括无状态转换和有状态转换。<br>
无状态转换：每个批次的处理不依赖于之前批次的数据。<br>
有状态转换：当前批次的处理需要使用之前批次的数据或者中间结果。有状态转换包括基于滑动窗口的转换和追踪状态变化的转换(updateStateByKey)。<br>
<span id="more-1747"></span></p>
<h1>DStream无状态转换操作</h1>
<p>下面给出一些无状态转换操作的含义：<br>
* map(func) ：对源DStream的每个元素，采用func函数进行转换，得到一个新的DStream；<br>
* flatMap(func)： 与map相似，但是每个输入项可用被映射为0个或者多个输出项；<br>
* filter(func)： 返回一个新的DStream，仅包含源DStream中满足函数func的项；<br>
* repartition(numPartitions)： 通过创建更多或者更少的分区改变DStream的并行程度；<br>
* union(otherStream)： 返回一个新的DStream，包含源DStream和其他DStream的元素；<br>
* count()：统计源DStream中每个RDD的元素数量；<br>
* reduce(func)：利用函数func聚集源DStream中每个RDD的元素，返回一个包含单元素RDDs的新DStream；<br>
* countByValue()：应用于元素类型为K的DStream上，返回一个（K，V）键值对类型的新DStream，每个键的值是在原DStream的每个RDD中的出现次数；<br>
* reduceByKey(func, [numTasks])：当在一个由(K,V)键值对组成的DStream上执行该操作时，返回一个新的由(K,V)键值对组成的DStream，每一个key的值均由给定的recuce函数（func）聚集起来；<br>
* join(otherStream, [numTasks])：当应用于两个DStream（一个包含（K,V）键值对,一个包含(K,W)键值对），返回一个包含(K, (V, W))键值对的新DStream；<br>
* cogroup(otherStream, [numTasks])：当应用于两个DStream（一个包含（K,V）键值对,一个包含(K,W)键值对），返回一个包含(K, Seq[V], Seq[W])的元组；<br>
* transform(func)：通过对源DStream的每个RDD应用RDD-to-RDD函数，创建一个新的DStream。支持在新的DStream中做任何RDD操作。</p>
<p>无状态转换操作实例：我们之前“<a href="http://dblab.xmu.edu.cn/blog/1741-2/" target="_blank">套接字流</a>”部分介绍的词频统计，就是采用无状态转换，每次统计，都是只统计当前批次到达的单词的词频，和之前批次无关，不会进行累计。</p>
<h1>DStream有状态转换操作</h1>
<p>对于DStream有状态转换操作而言，当前批次的处理需要使用之前批次的数据或者中间结果。有状态转换包括基于滑动窗口的转换和追踪状态变化(updateStateByKey)的转换。</p>
<h2>滑动窗口转换操作</h2>
<p>滑动窗口转换操作的计算过程如下图所示，我们可以事先设定一个滑动窗口的长度（也就是窗口的持续时间），并且设定滑动窗口的时间间隔（每隔多长时间
执行一次计算），然后，就可以让窗口按照指定时间间隔在源DStream上滑动，每次窗口停放的位置上，都会有一部分DStream被框入窗口内，形成一
个小段的DStream，这时，就可以启动对这个小段DStream的计算。<br>
<img src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/SparkStreaming.png" alt=""><br>
图 滑动窗口的计算过程</p>
<p>下面给给出一些窗口转换操作的含义：<br>
* window(windowLength, slideInterval) 基于源DStream产生的窗口化的批数据，计算得到一个新的DStream；<br>
* countByWindow(windowLength, slideInterval) 返回流中元素的一个滑动窗口数；<br>
* reduceByWindow(func, windowLength, slideInterval) 返回一个单元素流。利用函数func聚集滑动时间间隔的流的元素创建这个单元素流。函数func必须满足结合律，从而可以支持并行计算；<br>
* reduceByKeyAndWindow(func, windowLength, slideInterval, [numTasks]) 
应用到一个(K,V)键值对组成的DStream上时，会返回一个由(K,V)键值对组成的新的DStream。每一个key的值均由给定的reduce
函数(func函数)进行聚合计算。注意：在默认情况下，这个算子利用了Spark默认的并发任务数去分组。可以通过numTasks参数的设置来指定不
同的任务数；<br>
* reduceByKeyAndWindow(func, invFunc, windowLength, slideInterval, 
[numTasks]) 
更加高效的reduceByKeyAndWindow，每个窗口的reduce值，是基于先前窗口的reduce值进行增量计算得到的；它会对进入滑动窗
口的新数据进行reduce操作，并对离开窗口的老数据进行“逆向reduce”操作。但是，只能用于“可逆reduce函数”，即那些reduce函数
都有一个对应的“逆向reduce函数”（以InvFunc参数传入）；<br>
* countByValueAndWindow(windowLength, slideInterval, [numTasks]) 
当应用到一个(K,V)键值对组成的DStream上，返回一个由(K,V)键值对组成的新的DStream。每个key的值都是它们在滑动窗口中出现的
频率。</p>
<h2>updateStateByKey操作</h2>
<p>当我们需要在跨批次之间维护状态时，就必须使用updateStateByKey操作。<br>
下面我们就给出一个具体实例。我们还是以前面在“<a href="http://dblab.xmu.edu.cn/blog/1741-2/" target="_blank">套接字流</a>”
部分讲过的NetworkWordCount为例子来介绍，在之前的套接字流的介绍中，我们统计单词词频采用的是无状态转换操作，也就是说，每个批次的单
词发送给NetworkWordCount程序处理时，NetworkWordCount只对本批次内的单词进行词频统计，不会考虑之前到达的批次的单
词，所以，不同批次的单词词频都是独立统计的。<br>
对于有状态转换操作而言，本批次的词频统计，会在之前批次的词频统计结果的基础上进行不断累加，所以，最终统计得到的词频，是所有批次的单词的总的词频统计结果。<br>
下面，我们来改造一下在套接字流介绍过的NetworkWordCount程序。<br>
请登录Linux系统，打开一个终端，然后，执行下面命令：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">cd </span><span class="pln">/usr/local/spark/mycode/streaming  //这个streaming目录是之前已经创建好的</span></li><li class="L1"><span class="kwd">vim </span><span class="pln">NetworkWordCountStateful.py</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>上面使用vim编辑器新建了一个NetworkWordCountStateful.py代码文件，请在里面输入以下代码：</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-python prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="kwd">from</span><span class="pln"> __future__ </span><span class="kwd">import</span><span class="pln"> print_function</span></li><li class="L1"><span class="pln">&nbsp;</span></li><li class="L2"><span class="kwd">import</span><span class="pln"> sys</span></li><li class="L3"><span class="pln">&nbsp;</span></li><li class="L4"><span class="kwd">from</span><span class="pln"> pyspark </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">SparkContext</span></li><li class="L5"><span class="kwd">from</span><span class="pln"> pyspark</span><span class="pun">.</span><span class="pln">streaming </span><span class="kwd">import</span><span class="pln"> </span><span class="typ">StreamingContext</span></li><li class="L6"><span class="pln">&nbsp;</span></li><li class="L7"><span class="kwd">if</span><span class="pln"> __name__ </span><span class="pun">==</span><span class="pln"> </span><span class="str">"__main__"</span><span class="pun">:</span></li><li class="L8"><span class="pln">    </span><span class="kwd">if</span><span class="pln"> len</span><span class="pun">(</span><span class="pln">sys</span><span class="pun">.</span><span class="pln">argv</span><span class="pun">)</span><span class="pln"> </span><span class="pun">!=</span><span class="pln"> </span><span class="lit">3</span><span class="pun">:</span></li><li class="L9"><span class="pln">        </span><span class="kwd">print</span><span class="pun">(</span><span class="str">"Usage: stateful_network_wordcount.py &lt;hostname&gt; &lt;port&gt;"</span><span class="pun">,</span><span class="pln"> file</span><span class="pun">=</span><span class="pln">sys</span><span class="pun">.</span><span class="pln">stderr</span><span class="pun">)</span></li><li class="L0"><span class="pln">        exit</span><span class="pun">(-</span><span class="lit">1</span><span class="pun">)</span></li><li class="L1"><span class="pln">    sc </span><span class="pun">=</span><span class="pln"> </span><span class="typ">SparkContext</span><span class="pun">(</span><span class="pln">appName</span><span class="pun">=</span><span class="str">"PythonStreamingStatefulNetworkWordCount"</span><span class="pun">)</span></li><li class="L2"><span class="pln">    ssc </span><span class="pun">=</span><span class="pln"> </span><span class="typ">StreamingContext</span><span class="pun">(</span><span class="pln">sc</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)</span></li><li class="L3"><span class="pln">    ssc</span><span class="pun">.</span><span class="pln">checkpoint</span><span class="pun">(</span><span class="str">"file:///usr/local/spark/mycode/streaming/"</span><span class="pun">)</span></li><li class="L4"><span class="pln">&nbsp;</span></li><li class="L5"><span class="pln">    </span><span class="com"># RDD with initial state (key, value) pairs</span></li><li class="L6"><span class="pln">    initialStateRDD </span><span class="pun">=</span><span class="pln"> sc</span><span class="pun">.</span><span class="pln">parallelize</span><span class="pun">([(</span><span class="pln">u</span><span class="str">'hello'</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">),</span><span class="pln"> </span><span class="pun">(</span><span class="pln">u</span><span class="str">'world'</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">)])</span></li><li class="L7"><span class="pln">&nbsp;</span></li><li class="L8"><span class="pln">    </span><span class="kwd">def</span><span class="pln"> updateFunc</span><span class="pun">(</span><span class="pln">new_values</span><span class="pun">,</span><span class="pln"> last_sum</span><span class="pun">):</span></li><li class="L9"><span class="pln">        </span><span class="kwd">return</span><span class="pln"> sum</span><span class="pun">(</span><span class="pln">new_values</span><span class="pun">)</span><span class="pln"> </span><span class="pun">+</span><span class="pln"> </span><span class="pun">(</span><span class="pln">last_sum </span><span class="kwd">or</span><span class="pln"> </span><span class="lit">0</span><span class="pun">)</span></li><li class="L0"><span class="pln">&nbsp;</span></li><li class="L1"><span class="pln">    lines </span><span class="pun">=</span><span class="pln"> ssc</span><span class="pun">.</span><span class="pln">socketTextStream</span><span class="pun">(</span><span class="pln">sys</span><span class="pun">.</span><span class="pln">argv</span><span class="pun">[</span><span class="lit">1</span><span class="pun">],</span><span class="pln"> int</span><span class="pun">(</span><span class="pln">sys</span><span class="pun">.</span><span class="pln">argv</span><span class="pun">[</span><span class="lit">2</span><span class="pun">]))</span></li><li class="L2"><span class="pln">    running_counts </span><span class="pun">=</span><span class="pln"> lines</span><span class="pun">.</span><span class="pln">flatMap</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> line</span><span class="pun">:</span><span class="pln"> line</span><span class="pun">.</span><span class="pln">split</span><span class="pun">(</span><span class="str">" "</span><span class="pun">))</span><span class="pln">\</span></li><li class="L3"><span class="pln">                          </span><span class="pun">.</span><span class="pln">map</span><span class="pun">(</span><span class="kwd">lambda</span><span class="pln"> word</span><span class="pun">:</span><span class="pln"> </span><span class="pun">(</span><span class="pln">word</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">))</span><span class="pln">\</span></li><li class="L4"><span class="pln">                          </span><span class="pun">.</span><span class="pln">updateStateByKey</span><span class="pun">(</span><span class="pln">updateFunc</span><span class="pun">,</span><span class="pln"> initialRDD</span><span class="pun">=</span><span class="pln">initialStateRDD</span><span class="pun">)</span></li><li class="L5"><span class="pln">&nbsp;</span></li><li class="L6"><span class="pln">    running_counts</span><span class="pun">.</span><span class="pln">pprint</span><span class="pun">()</span></li><li class="L7"><span class="pln">&nbsp;</span></li><li class="L8"><span class="pln">    ssc</span><span class="pun">.</span><span class="pln">start</span><span class="pun">()</span></li><li class="L9"><span class="pln">    ssc</span><span class="pun">.</span><span class="pln">awaitTermination</span><span class="pun">()</span></li><li class="L0"><span class="pln">&nbsp;</span></li><li class="L1"><span class="pln">&nbsp;</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Python</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>保存该文件退出vim编辑器。<br>
这里要对这段代码中新增的updataStateByKey稍微解释一下。Spark 
Streaming的updateStateByKey可以把DStream中的数据按key做reduce操作，然后对各个批次的数据进行累加。注
意，wordDstream.updateStateByKeyInt每次传递给updateFunc函数两个参数，其中，第一个参数是某个key（即某
个单词）的当前批次的一系列值的列表 ,updateFunc函数中 
sum(new_values)，就是计算这个被传递进来的与某个key对应的当前批次的所有值的总和，也就是当前批次某个单词的出现次数。传递给
updateFunc函数的第二个参数是某个key的历史状态信息，也就是某个单词历史批次的词频汇总结果。<br>
退出vim编辑器。然后执行如下命令</p>
<div class="code-pretty-container"><pre class="prettyprint linenums lang-bash prettyprinted" style=""><ol class="linenums"><li class="L0"><span class="pln">python3 ./NetworkWordCountStateful.py localhost 9999</span></li></ol></pre><div class="code-pretty-toolbar"><span class="title">Shell 命令</span><a href="javascript:void(0);" title="复制代码" class="tool clipboard"><i class="fa fa-files-o"></i></a><a href="javascript:void(0);" title="查看纯文本代码" class="tool view-source"><i class="fa fa-code"></i></a><a href="javascript:void(0);" title="返回代码高亮" class="tool back-to-pretty"><i class="fa fa-undo"></i></a><span class="msg"></span></div></div>
<p>执行上面命令后，就进入了监听状态（我们把运行这个监听程序的窗口称为监听窗口），这时，你就可以像刚才一样，新打开一个窗口作为nc窗口，启动nc程序：</p>
<pre><code>nc -lk 9999
//在这个窗口中手动输入一些单词
hadoop
spark
hadoop
spark
hadoop
spark
</code></pre>
<p>然后，你切换到刚才的监听窗口，会发现，已经输出了词频统计信息：</p>
<pre><code>-------------------------------------------
Time: 1479890485000 ms
-------------------------------------------
(spark,1)
(hadoop,1)

-------------------------------------------
Time: 1479890490000 ms
-------------------------------------------
(spark,2)
(hadoop,3)
</code></pre>
<p>从词频统计信息可以看出，词频统计是不断累加的，也就是有状态的转换。到此，实验顺利结束！</p>
			</div><!-- .entry-content -->

	<footer class="entry-footer">
		<div class="entry-author">
			<div class="author-title">本文作者</div>
			
		<div class="author-avatar"><img src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/2.jpg" alt="阮榕城" class="avatar avatar-thumbnail wp-user-avatar wp-user-avatar-thumbnail alignnone photo"></div>
		<div class="author-info">
			<p class="author-name"><a href="http://dblab.xmu.edu.cn/blog/author/ruanrongcheng/">阮榕城</a></p>
			<p class="author-desc">磨人的小妖精！</p>
			<p class="author-contact"><a href="http://www.nekomiao.me/" target="_blank" title="个人主页" class="homepage"><i class="fa fa-home"></i>www.nekomiao.me</a><i class="fa fa-envelope"></i><span class="envelope">moc.qq@crnaur</span></p>
		</div>
			</div>
		<div class="entry-info">
			<span class="permalink"><i class="fa fa-external-link"></i> <a href="http://dblab.xmu.edu.cn/blog/1747-2/" title="Spark2.1.0+入门：DStream转换操作(Python版)">http://dblab.xmu.edu.cn/blog/1747-2/</a></span><span class="category"><i class="fa fa-folder-open-o"></i> <a href="http://dblab.xmu.edu.cn/blog/category/big-data/" rel="category tag">大数据</a></span>		</div>
		<div class="yarpp-related yarpp-related-none">
</div>
	</footer><!-- .entry-footer -->
</article><!-- #post-## -->
			</div>
</div><!-- .row -->

	<div class="row">
		<div class="col-sm-3"></div>
		<div class="col-sm-9 site-footer">
			© 2014 <a href="http://dblab.xmu.edu.cn/">厦大数据库实验室</a>
					</div>
	</div>
</div><!-- .container -->
<link rel="stylesheet" id="yarppRelatedCss-css" href="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/related.css" type="text/css" media="all">
<script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/prettify.js"></script>
<script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/power.js"></script>
<script type="text/javascript" src="5.9Spark2.1.0+%E5%85%A5%E9%97%A8%EF%BC%9ADStream%E8%BD%AC%E6%8D%A2%E6%93%8D%E4%BD%9C(Python%E7%89%88)_%E5%8E%A6%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%8D%9A%E5%AE%A2_files/wp-embed.js"></script>

<div class="back-to-top" id="back-to-top" title="嗖的就上去了！" style="display: none;"><span><i class="fa fa-chevron-up"></i></span></div></body></html>